{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding inputs: 100%|██████████| 238/238 [00:09<00:00, 25.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the index on input vectors...\n",
      "Index training completed.\n",
      "Adding input vectors to the index...\n",
      "Input vectors added to the index.\n",
      "Searching for most similar reference for input: 'of his spine. There were times when it went on and on until the cruel, wicked, unforgivable thing seemed to him not that the guards continued to beat him but that he could not force hirnself into losing consciousness. There were times when his nerve so forsook him that he began shouting for mercy even before the beating began, when the mere sight of a fist drawn back for a blow was enough to make him pour forth a confession of real and imaginary crimes. There were other times when he started out with the resolve of confessing nothing, when every word had to be forced out of him between gasps of pain, and there were times when he feebly tried to compromise, when he said to himself: 'I will confess, but not yet. I must hold out till the pain becomes unbearable. Three more kicks, two more kicks, and then I will tell them what they want.' Sometimes he was beaten till he could hardly stand, then flung like a sack of potatoes on to the stone floor of a'...\n",
      "Most similar reference: ['cell, left to recuperate for a few hours, and then taken out and beaten again. There were also longer periods of recovery. He remembered them dimly, because they were spent chiefly in sleep or stupor. He remembered a cell with a plank bed, a sort of shelf sticking out from']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "model = model.to(device)\n",
    "\n",
    "# Load JSON data and prepare pairs\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for non-infringement\n",
    "    non_infringement_inputs = [entry['input'] for entry in non_infringement_json_data]\n",
    "    non_infringement_references = [entry['reference'] for entry in non_infringement_json_data]\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for infringement\n",
    "    infringement_inputs = [entry['input'] for entry in infringement_json_data]\n",
    "    infringement_references = [entry['reference'] for entry in infringement_json_data]\n",
    "\n",
    "    # Create structured matching pairs\n",
    "    non_infringement_pairs = list(zip(non_infringement_inputs, non_infringement_references))\n",
    "    infringement_pairs = list(zip(infringement_inputs, infringement_references))\n",
    "\n",
    "    # Combine all pairs into a single list\n",
    "    all_pairs = non_infringement_pairs + infringement_pairs\n",
    "    return all_pairs\n",
    "\n",
    "# Example usage\n",
    "all_pairs = load_data(\n",
    "    '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.non_infringement.json',\n",
    "    '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.infringement.json'\n",
    ")\n",
    "\n",
    "# Extract `input` texts for embedding\n",
    "input_texts = [pair[0] for pair in all_pairs]\n",
    "references = [pair[1] for pair in all_pairs]\n",
    "\n",
    "# Encode `input` texts in batches\n",
    "def batch_encode_texts(model, texts, batch_size=8):\n",
    "    all_vectors = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding inputs\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        batch_vectors = model.encode(batch, convert_to_tensor=True, device=device)\n",
    "        all_vectors.append(batch_vectors.cpu().numpy())\n",
    "    return np.vstack(all_vectors)\n",
    "\n",
    "# Encode the `input` texts\n",
    "input_vectors = batch_encode_texts(model, input_texts)\n",
    "\n",
    "# Initialize FAISS index for `input` vectors\n",
    "dimension = input_vectors.shape[1]\n",
    "nlist = 3  # Example number of clusters\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "gpu_index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train and add vectors to the FAISS index\n",
    "print(\"Training the index on input vectors...\")\n",
    "gpu_index.train(input_vectors)\n",
    "print(\"Index training completed.\")\n",
    "print(\"Adding input vectors to the index...\")\n",
    "gpu_index.add(input_vectors)\n",
    "print(\"Input vectors added to the index.\")\n",
    "\n",
    "# Setting up SQLite database to store text and embeddings\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect('reference_db.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS reference_data (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            input_text TEXT NOT NULL,\n",
    "            reference_text TEXT NOT NULL,\n",
    "            embedding BLOB NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Store `input` and `reference` pairs in the database\n",
    "def store_pairs(conn, inputs, references, embeddings):\n",
    "    cursor = conn.cursor()\n",
    "    for inp, ref, emb in zip(inputs, references, embeddings):\n",
    "        cursor.execute('INSERT INTO reference_data (input_text, reference_text, embedding) VALUES (?, ?, ?)', \n",
    "                       (inp, ref, emb.tobytes()))\n",
    "    conn.commit()\n",
    "\n",
    "# Store pairs in the database\n",
    "conn = setup_database()\n",
    "store_pairs(conn, input_texts, references, input_vectors)\n",
    "\n",
    "# Function to find the most relevant reference based on input text\n",
    "def search_most_similar_reference(input_sentence, top_k=1):\n",
    "    print(f\"Searching for most similar reference for input: '{input_sentence}'...\")\n",
    "    input_vector = model.encode([input_sentence], convert_to_tensor=True, device=device).cpu().numpy()\n",
    "    _, indices = gpu_index.search(input_vector, top_k)\n",
    "    # Retrieve the most similar `input`'s corresponding `reference`\n",
    "    return [references[i] for i in indices[0]]\n",
    "\n",
    "\n",
    "\n",
    "# Example input sentence\n",
    "input_sentence = \"of his spine. There were times when it went on and on until the cruel, wicked, unforgivable thing seemed to him not that the guards continued to beat him but that he could not force hirnself into losing consciousness. There were times when his nerve so forsook him that he began shouting for mercy even before the beating began, when the mere sight of a fist drawn back for a blow was enough to make him pour forth a confession of real and imaginary crimes. There were other times when he started out with the resolve of confessing nothing, when every word had to be forced out of him between gasps of pain, and there were times when he feebly tried to compromise, when he said to himself: 'I will confess, but not yet. I must hold out till the pain becomes unbearable. Three more kicks, two more kicks, and then I will tell them what they want.' Sometimes he was beaten till he could hardly stand, then flung like a sack of potatoes on to the stone floor of a\"\n",
    "most_similar_reference = search_most_similar_reference(input_sentence)\n",
    "print(\"Most similar reference:\", most_similar_reference)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
