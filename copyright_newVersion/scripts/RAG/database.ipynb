{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding references: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s]\n",
      "WARNING clustering 7 points to 3 centroids: please provide at least 117 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the index...\n",
      "Index training completed.\n",
      "Adding vectors to the index...\n",
      "Vectors added to the index.\n",
      "Searching for next sentence for input: 'foes right and left. Ser Rodrik hammered at the big man in the shadowskin cloak, their horses dancing round each other as they traded blow for blow.'...\n",
      "Recommended next sentence: ['. Tyrion danced back in while the brigand\\'s leg was still pinned beneath his fallen mount, and buried the axe in the man\\'s neck, just above the shoulder blades. As he struggled to yank the blade loose, he heard Marillion moaning under the bodies. \"Someone help me,\" the singer']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to load data from JSON filesimport json\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for non-infringement\n",
    "    non_infringement_references = [entry['reference'] for entry in non_infringement_json_data]\n",
    "    y_non_infringement = [1] * len(non_infringement_outputs)\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for infringement\n",
    "    infringement_references = [entry['reference'] for entry in infringement_json_data]\n",
    "    y_infringement = [0] * len(infringement_outputs)\n",
    "\n",
    "    return (non_infringement_references, y_non_infringement, infringement_references, y_infringement)\n",
    "\n",
    "# Example usage\n",
    "non_infringement_references, y_non_infringement, \\\n",
    "infringement_references, y_infringement = load_data('/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.non_infringement.json', '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.infringement.json')\n",
    "\n",
    "\n",
    "# Encode references in batches\n",
    "def batch_encode_references(model, references, batch_size=8):\n",
    "    all_vectors = []\n",
    "    for i in tqdm(range(0, len(references), batch_size), desc=\"Encoding references\"):\n",
    "        batch = references[i:i + batch_size]\n",
    "        batch_vectors = model.encode(batch, convert_to_tensor=True, device=device)\n",
    "        all_vectors.append(batch_vectors.cpu().numpy())\n",
    "    return np.vstack(all_vectors)\n",
    "\n",
    "# Encode the complete references\n",
    "reference_vectors = batch_encode_references(model, references)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = reference_vectors.shape[1]\n",
    "nlist = 3\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "gpu_index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train and add vectors to the FAISS index\n",
    "print(\"Training the index...\")\n",
    "gpu_index.train(reference_vectors)\n",
    "print(\"Index training completed.\")\n",
    "print(\"Adding vectors to the index...\")\n",
    "gpu_index.add(reference_vectors)\n",
    "print(\"Vectors added to the index.\")\n",
    "\n",
    "# Setting up SQLite database to store text and embeddings\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect('reference_db.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS reference_data (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            text TEXT NOT NULL,\n",
    "            embedding BLOB NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Function to store references and their embeddings directly in the database\n",
    "def store_references(conn, references, embeddings):\n",
    "    cursor = conn.cursor()\n",
    "    for ref, emb in zip(references, embeddings):\n",
    "        # Store each embedding as binary\n",
    "        cursor.execute('INSERT INTO reference_data (text, embedding) VALUES (?, ?)', \n",
    "                       (ref, emb.tobytes()))\n",
    "    conn.commit()\n",
    "\n",
    "# Store references in the database\n",
    "conn = setup_database()\n",
    "store_references(conn, references, reference_vectors)\n",
    "\n",
    "# Function to find the most relevant reference based on input text\n",
    "def search_next_sentence(input_text, top_k=1):\n",
    "    print(f\"Searching for next sentence for input: '{input_text}'...\")\n",
    "    input_vector = model.encode([input_text], convert_to_tensor=True, device=device).cpu().numpy()\n",
    "    _, indices = gpu_index.search(input_vector, top_k)\n",
    "    return [references[i] for i in indices[0]]\n",
    "\n",
    "# Example input sentence\n",
    "input_sentence = \"foes right and left. Ser Rodrik hammered at the big man in the shadowskin cloak, their horses dancing round each other as they traded blow for blow.\"\n",
    "next_sentence = search_next_sentence(input_sentence)\n",
    "print(\"Recommended next sentence:\", next_sentence)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
