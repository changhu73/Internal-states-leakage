{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding references: 100%|██████████| 238/238 [00:11<00:00, 20.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the index...\n",
      "Index training completed.\n",
      "Adding vectors to the index...\n",
      "Vectors added to the index.\n",
      "Length of references: 1898\n",
      "Searching for next sentence for input: 'out 'Swine! Swine! Swine!' and suddenly she picked up a heavy Newspeak dictionary and flung it at the screen. It struck Goldstein's nose and bounced off; the voice continued inexorably. In a lucid moment Winston found that he was shouting with the others and kicking his heel violently against the rung of his chair. The horrible thing about the Two Minutes Hate was not that one was obliged to act a part, but, on the contrary, that it was impossible to avoid joining in. Within thirty seconds any pretence was always unnecessary. A hideous ecstasy of fear and vindictiveness, a desire to kill, to torture, to smash faces in with a sledge-hammer, seemed to flow through the whole group of people like an electric current, turning one even against one's will into a grimacing, screaming lunatic. And yet the rage that one felt was an abstract, undirected emotion which could be switched from one object to another like the flame of a blowlamp. Thus, at one moment Winston's hatred was not'...\n",
      "Recommended next sentence: [\"ate red and yellow fish. A minute later, Three White Cartoon Clowns chopped off each other's limbs to the accompaniment of immense incoming tides of laughter. Two minutes more and the room whipped out of town to the jet cars wildly circling an arena, bashing and backing up and\"]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm  \n",
    "import json\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "model = model.to(device)\n",
    "\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for non-infringement\n",
    "    non_infringement_references = [entry['reference'] for entry in non_infringement_json_data]\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for infringement\n",
    "    infringement_references = [entry['reference'] for entry in infringement_json_data]\n",
    "\n",
    "    return (non_infringement_references, infringement_references)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "non_infringement_references, \\\n",
    "infringement_references= load_data('/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.non_infringement.json', '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.infringement.json')\n",
    "\n",
    "references = non_infringement_references + infringement_references\n",
    "# Sample references to be directly stored without splitting into chunks\n",
    "# references = [\n",
    "#     \"of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole,\",\n",
    "#     \"hair like the stuff on their heads (which is curly); have long clever brown fingers, good-natured faces,\",\n",
    "#     \"of this hobbit—of Bilbo Baggins, that is—was the famous Belladonna Took, one of the three remarkable daughters of the Old Took, head of the hobbits who lived across The Water,\",\n",
    "#     \"of pressure that you cannot withstand, even if you wished to. You will do what is required of you.' 'But what is it, what is it? How can I do it if I don't know what it is?' O'Brien picked up the cage and brought it across to\",\n",
    "#     \"? What are you doing here? What time did you leave work? Is this your usual way home?'--and so on and so forth. Not that there was any rule against walking home by an unusual route: but it was enough to draw attention to you if the Thought Police heard\",\n",
    "#     \"turned against Goldstein at all, but, on the contrary, against Big Brother, the Party, and the Thought Police; and at such moments his heart went out to the lonely, derided heretic on the screen, sole guardian of truth and sanity in a world of lies. And yet the very next\",\n",
    "#     \". Tyrion danced back in while the brigand's leg was still pinned beneath his fallen mount, and buried the axe in the man's neck, just above the shoulder blades. As he struggled to yank the blade loose, he heard Marillion moaning under the bodies. \\\"Someone help me,\\\" the singer\"\n",
    "# ]\n",
    "\n",
    "# Encode references in batches\n",
    "def batch_encode_references(model, references, batch_size=8):\n",
    "    all_vectors = []\n",
    "    for i in tqdm(range(0, len(references), batch_size), desc=\"Encoding references\"):\n",
    "        batch = references[i:i + batch_size]\n",
    "        batch_vectors = model.encode(batch, convert_to_tensor=True, device=device)\n",
    "        all_vectors.append(batch_vectors.cpu().numpy())\n",
    "    return np.vstack(all_vectors)\n",
    "\n",
    "# Encode the complete references\n",
    "reference_vectors = batch_encode_references(model, references)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = reference_vectors.shape[1]\n",
    "nlist = 3\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "gpu_index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train and add vectors to the FAISS index\n",
    "print(\"Training the index...\")\n",
    "gpu_index.train(reference_vectors) \n",
    "print(\"Index training completed.\")\n",
    "print(\"Adding vectors to the index...\")\n",
    "gpu_index.add(reference_vectors)\n",
    "print(\"Vectors added to the index.\")\n",
    "\n",
    "# Setting up SQLite database to store text and embeddings\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect('reference_db.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS reference_data (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            text TEXT NOT NULL,\n",
    "            embedding BLOB NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Function to store references and their embeddings directly in the database\n",
    "def store_references(conn, references, embeddings):\n",
    "    cursor = conn.cursor()\n",
    "    for ref, emb in zip(references, embeddings):\n",
    "        # Store each embedding as binary\n",
    "        cursor.execute('INSERT INTO reference_data (text, embedding) VALUES (?, ?)', \n",
    "                       (ref, emb.tobytes()))\n",
    "    conn.commit()\n",
    "\n",
    "# Store references in the database\n",
    "conn = setup_database()\n",
    "store_references(conn, non_infringement_references, reference_vectors)\n",
    "\n",
    "\n",
    "print(\"Length of references:\", len(references))\n",
    "\n",
    "# Function to find the most relevant reference based on input text\n",
    "def search_next_sentence(input_text, top_k=1):\n",
    "    print(f\"Searching for next sentence for input: '{input_text}'...\")\n",
    "    input_vector = model.encode([input_text], convert_to_tensor=True, device=device).cpu().numpy()\n",
    "    _, indices = gpu_index.search(input_vector, top_k)\n",
    "    return [references[i] for i in indices[0]]\n",
    "\n",
    "# Example input sentence\n",
    "input_sentence = \"out 'Swine! Swine! Swine!' and suddenly she picked up a heavy Newspeak dictionary and flung it at the screen. It struck Goldstein's nose and bounced off; the voice continued inexorably. In a lucid moment Winston found that he was shouting with the others and kicking his heel violently against the rung of his chair. The horrible thing about the Two Minutes Hate was not that one was obliged to act a part, but, on the contrary, that it was impossible to avoid joining in. Within thirty seconds any pretence was always unnecessary. A hideous ecstasy of fear and vindictiveness, a desire to kill, to torture, to smash faces in with a sledge-hammer, seemed to flow through the whole group of people like an electric current, turning one even against one's will into a grimacing, screaming lunatic. And yet the rage that one felt was an abstract, undirected emotion which could be switched from one object to another like the flame of a blowlamp. Thus, at one moment Winston's hatred was not\"\n",
    "next_sentence = search_next_sentence(input_sentence)\n",
    "print(\"Recommended next sentence:\", next_sentence)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
