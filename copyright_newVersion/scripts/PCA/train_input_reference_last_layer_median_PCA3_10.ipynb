{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guangwei/miniconda3/envs/sit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import packages & variables\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoModelForSequenceClassification\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "# Parameters\n",
    "model_name = 'meta-llama/Meta-Llama-3.1-8B'\n",
    "non_infringement_file = '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_10.non_infringement.json'\n",
    "infringement_file = '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_10.infringement.json'\n",
    "checkpoint_file = '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/models/train_input_reference_last_layer_PCA3_10.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CustumMLP for internal states train\n",
    "class CustomMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(CustomMLP, self).__init__()\n",
    "        self.down = nn.Linear(input_dim, hidden_dim)\n",
    "        self.gate = nn.Linear(input_dim, hidden_dim)\n",
    "        self.up = nn.Linear(hidden_dim, 1)\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        down_output = self.down(x)\n",
    "        gate_output = self.gate(x)\n",
    "        gated_output = down_output * self.activation(gate_output)\n",
    "        return self.up(gated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hidden states/reference embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "def extract_hidden_states(texts, model, tokenizer, apply_pca=True, n_components=3, batch_size=4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    hidden_states = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing data batches\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        hidden_state = outputs.hidden_states[-1].mean(dim=1).cpu().numpy()\n",
    "        hidden_states.append(hidden_state)\n",
    "\n",
    "    hidden_states = np.vstack(hidden_states)\n",
    "    \n",
    "    # 应用 PCA 降维\n",
    "    if apply_pca:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        hidden_states = pca.fit_transform(hidden_states)\n",
    "        print(f\"Hidden states reduced to {n_components} dimensions using PCA.\")\n",
    "        \n",
    "    return hidden_states\n",
    "\n",
    "def extract_reference_embeddings(references, model, tokenizer, batch_size=4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(references), batch_size), desc=\"Processing references\"):\n",
    "        batch_references = references[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_references, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.pooler_output.cpu().numpy())\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for infringement & non infringement\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    non_infringement_outputs = [entry['input'] for entry in non_infringement_json_data]\n",
    "    non_infringement_references = [entry['reference'] for entry in non_infringement_json_data]\n",
    "    y_non_infringement = [1] * len(non_infringement_outputs)\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    infringement_outputs = [entry['input'] for entry in infringement_json_data]\n",
    "    infringement_references = [entry['reference'] for entry in infringement_json_data]\n",
    "    y_infringement = [0] * len(infringement_outputs)\n",
    "\n",
    "    return non_infringement_outputs, non_infringement_references, y_non_infringement, infringement_outputs, infringement_references, y_infringement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for best model\n",
    "def train_model(X_train, y_train, X_test, y_test, input_dim, hidden_dim, epochs=2000, lr=0.001, checkpoint_path=checkpoint_file):\n",
    "    custom_mlp = CustomMLP(input_dim, hidden_dim)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(custom_mlp.parameters(), lr=lr)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    best_accuracy = -float('inf')\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "        custom_mlp.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = custom_mlp(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "            custom_mlp.eval()\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                y_pred_logits = custom_mlp(X_test_tensor)\n",
    "                y_pred = (torch.sigmoid(y_pred_logits) > 0.5).float().numpy()\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Test Accuracy at Epoch {epoch + 1}: {accuracy * 100:.2f}%\")\n",
    "            \n",
    "            report = classification_report(y_test, y_pred, target_names=[\"infringement\", \"non_infringement\"])\n",
    "            print(f\"Classification Report at Epoch {epoch + 1}:\\n{report}\")\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model_state = custom_mlp.state_dict()\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(best_model_state, checkpoint_path)\n",
    "                print(f\"New best model saved with accuracy {best_accuracy * 100:.2f}% at epoch {best_epoch}\")\n",
    "                print(f\"Best Classification Report at Epoch {best_epoch}:\\n{report}\")\n",
    "\n",
    "    custom_mlp.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Final Model Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return custom_mlp, losses, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]\n",
      "/home/guangwei/miniconda3/envs/sit/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('google-bert/bert-base-uncased')\n",
    "bert_tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "non_infringement_outputs, non_infringement_references, y_non_infringement, infringement_outputs, infringement_references, y_infringement = load_data(\n",
    "    non_infringement_file, infringement_file\n",
    ")\n",
    "\n",
    "y_non_infringement = np.array(y_non_infringement)\n",
    "y_infringement = np.array(y_infringement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting hidden states for non_infringement texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data batches:   0%|          | 0/65 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Processing data batches: 100%|██████████| 65/65 [00:16<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden states reduced to 3 dimensions using PCA.\n",
      "Extracting reference embeddings for non_infringement texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing references: 100%|██████████| 65/65 [00:00<00:00, 91.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting hidden states for infringement texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data batches: 100%|██████████| 81/81 [00:24<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden states reduced to 3 dimensions using PCA.\n",
      "Extracting reference embeddings for infringement texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing references: 100%|██████████| 81/81 [00:00<00:00, 101.95it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting hidden states for non_infringement texts...\")\n",
    "X_non_infringement = extract_hidden_states(non_infringement_outputs, model, tokenizer)\n",
    "print(\"Extracting reference embeddings for non_infringement texts...\")\n",
    "reference_embeddings_non_infringement = extract_reference_embeddings(non_infringement_references, bert_model, bert_tokenizer)\n",
    "X_non_infringement_combined = np.hstack([X_non_infringement, reference_embeddings_non_infringement])\n",
    "\n",
    "print(\"Extracting hidden states for infringement texts...\")\n",
    "X_infringement = extract_hidden_states(infringement_outputs, model, tokenizer)\n",
    "print(\"Extracting reference embeddings for infringement texts...\")\n",
    "reference_embeddings_infringement = extract_reference_embeddings(infringement_references, bert_model, bert_tokenizer)\n",
    "X_infringement_combined = np.hstack([X_infringement, reference_embeddings_infringement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into training and test sets.\n"
     ]
    }
   ],
   "source": [
    "split_index_non_infringement = int(0.8 * len(X_non_infringement_combined))\n",
    "X_non_infringement_train = X_non_infringement_combined[:split_index_non_infringement]\n",
    "X_non_infringement_test = X_non_infringement_combined[split_index_non_infringement:]\n",
    "y_non_infringement_train = y_non_infringement[:split_index_non_infringement]\n",
    "y_non_infringement_test = y_non_infringement[split_index_non_infringement:]\n",
    "\n",
    "split_index_infringement = int(0.8 * len(X_infringement_combined))\n",
    "X_infringement_train = X_infringement_combined[:split_index_infringement]\n",
    "X_infringement_test = X_infringement_combined[split_index_infringement:]\n",
    "y_infringement_train = y_infringement[:split_index_infringement]\n",
    "y_infringement_test = y_infringement[split_index_infringement:]\n",
    "\n",
    "X_train = np.vstack((X_non_infringement_train, X_infringement_train))\n",
    "X_test = np.vstack((X_non_infringement_test, X_infringement_test))\n",
    "y_train = np.concatenate((y_non_infringement_train, y_infringement_train))\n",
    "y_test = np.concatenate((y_non_infringement_test, y_infringement_test))\n",
    "\n",
    "print(\"Data successfully split into training and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP model with input_dim=771 and hidden_dim=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 1/2000 [00:00<03:36,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000, Loss: 0.5052\n",
      "Test Accuracy at Epoch 10: 44.44%\n",
      "Classification Report at Epoch 10:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.50      0.40      0.44        65\n",
      "non_infringement       0.40      0.50      0.44        52\n",
      "\n",
      "        accuracy                           0.44       117\n",
      "       macro avg       0.45      0.45      0.44       117\n",
      "    weighted avg       0.46      0.44      0.44       117\n",
      "\n",
      "New best model saved with accuracy 44.44% at epoch 10\n",
      "Best Classification Report at Epoch 10:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.50      0.40      0.44        65\n",
      "non_infringement       0.40      0.50      0.44        52\n",
      "\n",
      "        accuracy                           0.44       117\n",
      "       macro avg       0.45      0.45      0.44       117\n",
      "    weighted avg       0.46      0.44      0.44       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▏         | 31/2000 [00:00<00:17, 113.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/2000, Loss: 0.2948\n",
      "Test Accuracy at Epoch 20: 57.26%\n",
      "Classification Report at Epoch 20:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.57      0.60        65\n",
      "non_infringement       0.52      0.58      0.55        52\n",
      "\n",
      "        accuracy                           0.57       117\n",
      "       macro avg       0.57      0.57      0.57       117\n",
      "    weighted avg       0.58      0.57      0.57       117\n",
      "\n",
      "New best model saved with accuracy 57.26% at epoch 20\n",
      "Best Classification Report at Epoch 20:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.57      0.60        65\n",
      "non_infringement       0.52      0.58      0.55        52\n",
      "\n",
      "        accuracy                           0.57       117\n",
      "       macro avg       0.57      0.57      0.57       117\n",
      "    weighted avg       0.58      0.57      0.57       117\n",
      "\n",
      "Epoch 30/2000, Loss: 0.1772\n",
      "Test Accuracy at Epoch 30: 58.12%\n",
      "Classification Report at Epoch 30:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.57      0.60        65\n",
      "non_infringement       0.53      0.60      0.56        52\n",
      "\n",
      "        accuracy                           0.58       117\n",
      "       macro avg       0.58      0.58      0.58       117\n",
      "    weighted avg       0.59      0.58      0.58       117\n",
      "\n",
      "New best model saved with accuracy 58.12% at epoch 30\n",
      "Best Classification Report at Epoch 30:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.57      0.60        65\n",
      "non_infringement       0.53      0.60      0.56        52\n",
      "\n",
      "        accuracy                           0.58       117\n",
      "       macro avg       0.58      0.58      0.58       117\n",
      "    weighted avg       0.59      0.58      0.58       117\n",
      "\n",
      "Epoch 40/2000, Loss: 0.1029\n",
      "Test Accuracy at Epoch 40: 59.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   3%|▎         | 58/2000 [00:00<00:16, 114.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 40:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "New best model saved with accuracy 59.83% at epoch 40\n",
      "Best Classification Report at Epoch 40:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "Epoch 50/2000, Loss: 0.0570\n",
      "Test Accuracy at Epoch 50: 59.83%\n",
      "Classification Report at Epoch 50:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.68      0.52      0.59        65\n",
      "non_infringement       0.54      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.61      0.61      0.60       117\n",
      "    weighted avg       0.62      0.60      0.60       117\n",
      "\n",
      "Epoch 60/2000, Loss: 0.0296\n",
      "Test Accuracy at Epoch 60: 61.54%\n",
      "Classification Report at Epoch 60:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.55      0.62        65\n",
      "non_infringement       0.55      0.69      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.62      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.62       117\n",
      "\n",
      "New best model saved with accuracy 61.54% at epoch 60\n",
      "Best Classification Report at Epoch 60:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.55      0.62        65\n",
      "non_infringement       0.55      0.69      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.62      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   4%|▍         | 87/2000 [00:00<00:17, 106.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/2000, Loss: 0.0157\n",
      "Test Accuracy at Epoch 70: 52.99%\n",
      "Classification Report at Epoch 70:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.45      0.51        65\n",
      "non_infringement       0.48      0.63      0.55        52\n",
      "\n",
      "        accuracy                           0.53       117\n",
      "       macro avg       0.54      0.54      0.53       117\n",
      "    weighted avg       0.55      0.53      0.53       117\n",
      "\n",
      "Epoch 80/2000, Loss: 0.0084\n",
      "Test Accuracy at Epoch 80: 54.70%\n",
      "Classification Report at Epoch 80:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.45      0.52        65\n",
      "non_infringement       0.49      0.67      0.57        52\n",
      "\n",
      "        accuracy                           0.55       117\n",
      "       macro avg       0.56      0.56      0.55       117\n",
      "    weighted avg       0.57      0.55      0.54       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   6%|▌         | 117/2000 [00:01<00:14, 125.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/2000, Loss: 0.0050\n",
      "Test Accuracy at Epoch 90: 52.99%\n",
      "Classification Report at Epoch 90:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.45      0.51        65\n",
      "non_infringement       0.48      0.63      0.55        52\n",
      "\n",
      "        accuracy                           0.53       117\n",
      "       macro avg       0.54      0.54      0.53       117\n",
      "    weighted avg       0.55      0.53      0.53       117\n",
      "\n",
      "Epoch 100/2000, Loss: 0.0032\n",
      "Test Accuracy at Epoch 100: 52.99%\n",
      "Classification Report at Epoch 100:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.45      0.51        65\n",
      "non_infringement       0.48      0.63      0.55        52\n",
      "\n",
      "        accuracy                           0.53       117\n",
      "       macro avg       0.54      0.54      0.53       117\n",
      "    weighted avg       0.55      0.53      0.53       117\n",
      "\n",
      "Epoch 110/2000, Loss: 0.0022\n",
      "Test Accuracy at Epoch 110: 59.83%\n",
      "Classification Report at Epoch 110:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "Epoch 120/2000, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   7%|▋         | 132/2000 [00:01<00:14, 131.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy at Epoch 120: 59.83%\n",
      "Classification Report at Epoch 120:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "Epoch 130/2000, Loss: 0.0013\n",
      "Test Accuracy at Epoch 130: 59.83%\n",
      "Classification Report at Epoch 130:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "Epoch 140/2000, Loss: 0.0010\n",
      "Test Accuracy at Epoch 140: 59.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   8%|▊         | 160/2000 [00:01<00:15, 117.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 140:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "Epoch 150/2000, Loss: 0.0008\n",
      "Test Accuracy at Epoch 150: 59.83%\n",
      "Classification Report at Epoch 150:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.57      0.61        65\n",
      "non_infringement       0.54      0.63      0.58        52\n",
      "\n",
      "        accuracy                           0.60       117\n",
      "       macro avg       0.60      0.60      0.60       117\n",
      "    weighted avg       0.61      0.60      0.60       117\n",
      "\n",
      "Epoch 160/2000, Loss: 0.0007\n",
      "Test Accuracy at Epoch 160: 61.54%\n",
      "Classification Report at Epoch 160:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.57      0.62        65\n",
      "non_infringement       0.56      0.67      0.61        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.62      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   9%|▊         | 174/2000 [00:01<00:14, 123.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/2000, Loss: 0.0006\n",
      "Test Accuracy at Epoch 170: 61.54%\n",
      "Classification Report at Epoch 170:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.57      0.62        65\n",
      "non_infringement       0.56      0.67      0.61        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.62      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.62       117\n",
      "\n",
      "Epoch 180/2000, Loss: 0.0005\n",
      "Test Accuracy at Epoch 180: 62.39%\n",
      "Classification Report at Epoch 180:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.57      0.63        65\n",
      "non_infringement       0.56      0.69      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.63      0.62       117\n",
      "    weighted avg       0.64      0.62      0.62       117\n",
      "\n",
      "New best model saved with accuracy 62.39% at epoch 180\n",
      "Best Classification Report at Epoch 180:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.57      0.63        65\n",
      "non_infringement       0.56      0.69      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.63      0.62       117\n",
      "    weighted avg       0.64      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 217/2000 [00:01<00:14, 123.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/2000, Loss: 0.0004\n",
      "Test Accuracy at Epoch 190: 60.68%\n",
      "Classification Report at Epoch 190:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n",
      "Epoch 200/2000, Loss: 0.0004\n",
      "Test Accuracy at Epoch 200: 60.68%\n",
      "Classification Report at Epoch 200:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n",
      "Epoch 210/2000, Loss: 0.0003\n",
      "Test Accuracy at Epoch 210: 60.68%\n",
      "Classification Report at Epoch 210:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 230/2000 [00:02<00:18, 96.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/2000, Loss: 0.0003\n",
      "Test Accuracy at Epoch 220: 60.68%\n",
      "Classification Report at Epoch 220:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n",
      "Epoch 230/2000, Loss: 0.0003\n",
      "Test Accuracy at Epoch 230: 60.68%\n",
      "Classification Report at Epoch 230:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 260/2000 [00:02<00:14, 117.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/2000, Loss: 0.0002\n",
      "Test Accuracy at Epoch 240: 60.68%\n",
      "Classification Report at Epoch 240:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n",
      "Epoch 250/2000, Loss: 0.0002\n",
      "Test Accuracy at Epoch 250: 60.68%\n",
      "Classification Report at Epoch 250:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n",
      "Epoch 260/2000, Loss: 0.0002\n",
      "Test Accuracy at Epoch 260: 60.68%\n",
      "Classification Report at Epoch 260:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 289/2000 [00:02<00:14, 118.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/2000, Loss: 0.0002\n",
      "Test Accuracy at Epoch 270: 58.97%\n",
      "Classification Report at Epoch 270:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 280/2000, Loss: 0.0002\n",
      "Test Accuracy at Epoch 280: 58.97%\n",
      "Classification Report at Epoch 280:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 290/2000, Loss: 0.0002\n",
      "Test Accuracy at Epoch 290: 58.97%\n",
      "Classification Report at Epoch 290:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|█▌        | 317/2000 [00:02<00:14, 114.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 300: 58.97%\n",
      "Classification Report at Epoch 300:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 310/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 310: 58.97%\n",
      "Classification Report at Epoch 310:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 320/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 320: 58.97%\n",
      "Classification Report at Epoch 320:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  17%|█▋        | 347/2000 [00:03<00:12, 127.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 330: 58.97%\n",
      "Classification Report at Epoch 330:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 340/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 340: 58.97%\n",
      "Classification Report at Epoch 340:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 350/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 350: 58.97%\n",
      "Classification Report at Epoch 350:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  19%|█▉        | 377/2000 [00:03<00:13, 118.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 360: 58.97%\n",
      "Classification Report at Epoch 360:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 370/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 370: 58.97%\n",
      "Classification Report at Epoch 370:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 380/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 380: 58.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 409/2000 [00:03<00:11, 135.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 380:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 390/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 390: 58.97%\n",
      "Classification Report at Epoch 390:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 400/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 400: 58.97%\n",
      "Classification Report at Epoch 400:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 410/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 410: 58.97%\n",
      "Classification Report at Epoch 410:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|██▏       | 439/2000 [00:03<00:12, 124.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 420: 58.97%\n",
      "Classification Report at Epoch 420:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 430/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 430: 58.97%\n",
      "Classification Report at Epoch 430:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 440/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 440: 58.97%\n",
      "Classification Report at Epoch 440:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  23%|██▎       | 467/2000 [00:04<00:14, 108.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 450: 58.97%\n",
      "Classification Report at Epoch 450:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 460/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 460: 58.97%\n",
      "Classification Report at Epoch 460:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  25%|██▍       | 494/2000 [00:04<00:12, 118.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 470: 58.97%\n",
      "Classification Report at Epoch 470:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 480/2000, Loss: 0.0001\n",
      "Test Accuracy at Epoch 480: 58.97%\n",
      "Classification Report at Epoch 480:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 490/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 490: 58.97%\n",
      "Classification Report at Epoch 490:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  25%|██▌       | 508/2000 [00:04<00:12, 122.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 500: 58.97%\n",
      "Classification Report at Epoch 500:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 510/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 510: 58.97%\n",
      "Classification Report at Epoch 510:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  27%|██▋       | 536/2000 [00:04<00:12, 116.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 520: 58.97%\n",
      "Classification Report at Epoch 520:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.51      0.58        65\n",
      "non_infringement       0.53      0.69      0.60        52\n",
      "\n",
      "        accuracy                           0.59       117\n",
      "       macro avg       0.60      0.60      0.59       117\n",
      "    weighted avg       0.61      0.59      0.59       117\n",
      "\n",
      "Epoch 530/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 530: 60.68%\n",
      "Classification Report at Epoch 530:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.54      0.60        65\n",
      "non_infringement       0.55      0.69      0.61        52\n",
      "\n",
      "        accuracy                           0.61       117\n",
      "       macro avg       0.62      0.62      0.61       117\n",
      "    weighted avg       0.62      0.61      0.61       117\n",
      "\n",
      "Epoch 540/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 540: 61.54%\n",
      "Classification Report at Epoch 540:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  28%|██▊       | 566/2000 [00:04<00:12, 115.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 550: 61.54%\n",
      "Classification Report at Epoch 550:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 560/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 560: 61.54%\n",
      "Classification Report at Epoch 560:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 570/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 570: 61.54%\n",
      "Classification Report at Epoch 570:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|██▉       | 595/2000 [00:05<00:11, 126.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 580: 61.54%\n",
      "Classification Report at Epoch 580:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 590/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 590: 61.54%\n",
      "Classification Report at Epoch 590:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 600/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 600: 61.54%\n",
      "Classification Report at Epoch 600:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  31%|███       | 622/2000 [00:05<00:12, 106.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 610: 61.54%\n",
      "Classification Report at Epoch 610:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 620/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 620: 61.54%\n",
      "Classification Report at Epoch 620:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 630/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 630: 61.54%\n",
      "Classification Report at Epoch 630:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 640/2000, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  32%|███▏      | 640/2000 [00:05<00:11, 120.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy at Epoch 640: 61.54%\n",
      "Classification Report at Epoch 640:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 650/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 650: 61.54%\n",
      "Classification Report at Epoch 650:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  34%|███▍      | 681/2000 [00:05<00:11, 110.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 660: 61.54%\n",
      "Classification Report at Epoch 660:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 670/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 670: 61.54%\n",
      "Classification Report at Epoch 670:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 680/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 680: 61.54%\n",
      "Classification Report at Epoch 680:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  35%|███▌      | 707/2000 [00:06<00:12, 106.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 690: 61.54%\n",
      "Classification Report at Epoch 690:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 700/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 700: 61.54%\n",
      "Classification Report at Epoch 700:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 710/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 710: 61.54%\n",
      "Classification Report at Epoch 710:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  37%|███▋      | 736/2000 [00:06<00:11, 109.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 720: 61.54%\n",
      "Classification Report at Epoch 720:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 730/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 730: 61.54%\n",
      "Classification Report at Epoch 730:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 740/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 740: 61.54%\n",
      "Classification Report at Epoch 740:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  38%|███▊      | 764/2000 [00:06<00:10, 121.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 750: 61.54%\n",
      "Classification Report at Epoch 750:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 760/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 760: 61.54%\n",
      "Classification Report at Epoch 760:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n",
      "Epoch 770/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 770: 61.54%\n",
      "Classification Report at Epoch 770:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.54      0.61        65\n",
      "non_infringement       0.55      0.71      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.62      0.62       117\n",
      "    weighted avg       0.63      0.62      0.61       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 809/2000 [00:07<00:09, 127.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 780: 62.39%\n",
      "Classification Report at Epoch 780:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 790/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 790: 62.39%\n",
      "Classification Report at Epoch 790:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 800/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 800: 62.39%\n",
      "Classification Report at Epoch 800:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 810/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 810: 62.39%\n",
      "Classification Report at Epoch 810:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████▏     | 838/2000 [00:07<00:09, 118.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 820: 62.39%\n",
      "Classification Report at Epoch 820:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 830/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 830: 62.39%\n",
      "Classification Report at Epoch 830:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 840/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 840: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  44%|████▎     | 870/2000 [00:07<00:08, 133.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 840:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 850/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 850: 62.39%\n",
      "Classification Report at Epoch 850:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 860/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 860: 62.39%\n",
      "Classification Report at Epoch 860:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 870/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 870: 62.39%\n",
      "Classification Report at Epoch 870:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  45%|████▍     | 899/2000 [00:07<00:08, 128.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 880: 62.39%\n",
      "Classification Report at Epoch 880:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 890/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 890: 62.39%\n",
      "Classification Report at Epoch 890:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 900/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 900: 62.39%\n",
      "Classification Report at Epoch 900:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  46%|████▌     | 915/2000 [00:07<00:08, 135.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 910: 62.39%\n",
      "Classification Report at Epoch 910:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 920/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 920: 62.39%\n",
      "Classification Report at Epoch 920:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  47%|████▋     | 943/2000 [00:08<00:09, 115.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 930: 62.39%\n",
      "Classification Report at Epoch 930:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 940/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 940: 62.39%\n",
      "Classification Report at Epoch 940:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 950/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 950: 62.39%\n",
      "Classification Report at Epoch 950:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 960/2000, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  49%|████▉     | 975/2000 [00:08<00:07, 129.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy at Epoch 960: 62.39%\n",
      "Classification Report at Epoch 960:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 970/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 970: 62.39%\n",
      "Classification Report at Epoch 970:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 980/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 980: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 1004/2000 [00:08<00:08, 124.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 980:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 990/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 990: 62.39%\n",
      "Classification Report at Epoch 990:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1000/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1000: 62.39%\n",
      "Classification Report at Epoch 1000:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1010/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1010: 62.39%\n",
      "Classification Report at Epoch 1010:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  52%|█████▏    | 1034/2000 [00:08<00:08, 117.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1020: 62.39%\n",
      "Classification Report at Epoch 1020:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1030/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1030: 62.39%\n",
      "Classification Report at Epoch 1030:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1040/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1040: 62.39%\n",
      "Classification Report at Epoch 1040:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|█████▎    | 1067/2000 [00:09<00:06, 137.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1050/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1050: 62.39%\n",
      "Classification Report at Epoch 1050:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1060/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1060: 62.39%\n",
      "Classification Report at Epoch 1060:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1070/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1070: 62.39%\n",
      "Classification Report at Epoch 1070:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  55%|█████▌    | 1100/2000 [00:09<00:06, 130.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1080/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1080: 62.39%\n",
      "Classification Report at Epoch 1080:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1090/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1090: 62.39%\n",
      "Classification Report at Epoch 1090:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1100/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1100: 62.39%\n",
      "Classification Report at Epoch 1100:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1110/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1110: 62.39%\n",
      "Classification Report at Epoch 1110:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  57%|█████▋    | 1132/2000 [00:09<00:07, 121.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1120/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1120: 62.39%\n",
      "Classification Report at Epoch 1120:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1130/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1130: 62.39%\n",
      "Classification Report at Epoch 1130:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1140/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1140: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  58%|█████▊    | 1163/2000 [00:09<00:06, 134.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1140:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1150/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1150: 62.39%\n",
      "Classification Report at Epoch 1150:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1160/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1160: 62.39%\n",
      "Classification Report at Epoch 1160:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1170/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1170: 62.39%\n",
      "Classification Report at Epoch 1170:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|█████▉    | 1194/2000 [00:10<00:06, 117.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1180/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1180: 62.39%\n",
      "Classification Report at Epoch 1180:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1190/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1190: 62.39%\n",
      "Classification Report at Epoch 1190:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  61%|██████    | 1224/2000 [00:10<00:05, 131.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1200/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1200: 62.39%\n",
      "Classification Report at Epoch 1200:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1210/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1210: 62.39%\n",
      "Classification Report at Epoch 1210:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1220/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1220: 62.39%\n",
      "Classification Report at Epoch 1220:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1230/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1230: 62.39%\n",
      "Classification Report at Epoch 1230:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  64%|██████▎   | 1270/2000 [00:10<00:05, 139.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1240/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1240: 62.39%\n",
      "Classification Report at Epoch 1240:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1250/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1250: 62.39%\n",
      "Classification Report at Epoch 1250:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1260/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1260: 62.39%\n",
      "Classification Report at Epoch 1260:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1270/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1270: 62.39%\n",
      "Classification Report at Epoch 1270:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|██████▌   | 1301/2000 [00:10<00:05, 127.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1280/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1280: 62.39%\n",
      "Classification Report at Epoch 1280:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1290/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1290: 62.39%\n",
      "Classification Report at Epoch 1290:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1300/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1300: 62.39%\n",
      "Classification Report at Epoch 1300:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  67%|██████▋   | 1334/2000 [00:11<00:04, 139.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1310/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1310: 62.39%\n",
      "Classification Report at Epoch 1310:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1320/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1320: 62.39%\n",
      "Classification Report at Epoch 1320:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1330/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1330: 62.39%\n",
      "Classification Report at Epoch 1330:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1340/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1340: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  67%|██████▋   | 1349/2000 [00:11<00:05, 122.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1340:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1350/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1350: 62.39%\n",
      "Classification Report at Epoch 1350:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  69%|██████▉   | 1377/2000 [00:11<00:04, 126.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1360/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1360: 62.39%\n",
      "Classification Report at Epoch 1360:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1370/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1370: 62.39%\n",
      "Classification Report at Epoch 1370:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1380/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1380: 62.39%\n",
      "Classification Report at Epoch 1380:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 1407/2000 [00:11<00:04, 119.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1390: 62.39%\n",
      "Classification Report at Epoch 1390:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1400/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1400: 62.39%\n",
      "Classification Report at Epoch 1400:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1410/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1410: 62.39%\n",
      "Classification Report at Epoch 1410:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  72%|███████▏  | 1435/2000 [00:12<00:04, 115.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1420/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1420: 62.39%\n",
      "Classification Report at Epoch 1420:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1430/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1430: 62.39%\n",
      "Classification Report at Epoch 1430:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1440/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1440: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  73%|███████▎  | 1463/2000 [00:12<00:04, 125.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1440:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1450/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1450: 62.39%\n",
      "Classification Report at Epoch 1450:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1460/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1460: 62.39%\n",
      "Classification Report at Epoch 1460:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1470/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1470: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  74%|███████▍  | 1479/2000 [00:12<00:03, 133.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1470:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1480/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1480: 62.39%\n",
      "Classification Report at Epoch 1480:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1490/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1490: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  75%|███████▌  | 1506/2000 [00:12<00:04, 113.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1490:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1500/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1500: 62.39%\n",
      "Classification Report at Epoch 1500:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1510/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1510: 62.39%\n",
      "Classification Report at Epoch 1510:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  77%|███████▋  | 1533/2000 [00:12<00:04, 106.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1520/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1520: 62.39%\n",
      "Classification Report at Epoch 1520:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1530/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1530: 62.39%\n",
      "Classification Report at Epoch 1530:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1540/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1540: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  78%|███████▊  | 1566/2000 [00:13<00:03, 130.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1540:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1550/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1550: 62.39%\n",
      "Classification Report at Epoch 1550:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1560/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1560: 62.39%\n",
      "Classification Report at Epoch 1560:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1570/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1570: 62.39%\n",
      "Classification Report at Epoch 1570:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|███████▉  | 1598/2000 [00:13<00:03, 123.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1580/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1580: 62.39%\n",
      "Classification Report at Epoch 1580:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1590/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1590: 62.39%\n",
      "Classification Report at Epoch 1590:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1600/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1600: 62.39%\n",
      "Classification Report at Epoch 1600:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1610/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1610: 62.39%\n",
      "Classification Report at Epoch 1610:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  81%|████████▏ | 1629/2000 [00:13<00:03, 120.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1620: 62.39%\n",
      "Classification Report at Epoch 1620:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1630/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1630: 62.39%\n",
      "Classification Report at Epoch 1630:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1640/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1640: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  83%|████████▎ | 1659/2000 [00:13<00:02, 133.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1640:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1650/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1650: 62.39%\n",
      "Classification Report at Epoch 1650:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1660/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1660: 62.39%\n",
      "Classification Report at Epoch 1660:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1670/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1670: 62.39%\n",
      "Classification Report at Epoch 1670:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  85%|████████▍ | 1693/2000 [00:14<00:02, 126.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1680/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1680: 62.39%\n",
      "Classification Report at Epoch 1680:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1690/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1690: 62.39%\n",
      "Classification Report at Epoch 1690:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1700/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1700: 62.39%\n",
      "Classification Report at Epoch 1700:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  86%|████████▋ | 1728/2000 [00:14<00:01, 147.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1710/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1710: 62.39%\n",
      "Classification Report at Epoch 1710:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1720/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1720: 62.39%\n",
      "Classification Report at Epoch 1720:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1730/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1730: 62.39%\n",
      "Classification Report at Epoch 1730:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1740/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1740: 62.39%\n",
      "Classification Report at Epoch 1740:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  89%|████████▉ | 1778/2000 [00:14<00:01, 149.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1750: 62.39%\n",
      "Classification Report at Epoch 1750:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1760/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1760: 62.39%\n",
      "Classification Report at Epoch 1760:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1770/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1770: 62.39%\n",
      "Classification Report at Epoch 1770:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1780/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1780: 62.39%\n",
      "Classification Report at Epoch 1780:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|█████████ | 1810/2000 [00:14<00:01, 128.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1790/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1790: 62.39%\n",
      "Classification Report at Epoch 1790:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1800/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1800: 62.39%\n",
      "Classification Report at Epoch 1800:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1810/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1810: 62.39%\n",
      "Classification Report at Epoch 1810:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  92%|█████████▏| 1841/2000 [00:15<00:01, 138.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1820/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1820: 62.39%\n",
      "Classification Report at Epoch 1820:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1830/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1830: 62.39%\n",
      "Classification Report at Epoch 1830:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1840/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1840: 62.39%\n",
      "Classification Report at Epoch 1840:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  94%|█████████▎| 1872/2000 [00:15<00:00, 137.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1850/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1850: 62.39%\n",
      "Classification Report at Epoch 1850:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1860/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1860: 62.39%\n",
      "Classification Report at Epoch 1860:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1870/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1870: 62.39%\n",
      "Classification Report at Epoch 1870:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1880/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1880: 62.39%\n",
      "Classification Report at Epoch 1880:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  95%|█████████▌| 1908/2000 [00:15<00:00, 153.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1890/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1890: 62.39%\n",
      "Classification Report at Epoch 1890:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1900/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1900: 62.39%\n",
      "Classification Report at Epoch 1900:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1910/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1910: 62.39%\n",
      "Classification Report at Epoch 1910:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  97%|█████████▋| 1941/2000 [00:15<00:00, 139.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1920/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1920: 62.39%\n",
      "Classification Report at Epoch 1920:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1930/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1930: 62.39%\n",
      "Classification Report at Epoch 1930:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1940/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1940: 62.39%\n",
      "Classification Report at Epoch 1940:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1950/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1950: 62.39%\n",
      "Classification Report at Epoch 1950:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  99%|█████████▉| 1976/2000 [00:16<00:00, 131.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1960/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1960: 62.39%\n",
      "Classification Report at Epoch 1960:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1970/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1970: 62.39%\n",
      "Classification Report at Epoch 1970:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 1980/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1980: 62.39%\n",
      "Classification Report at Epoch 1980:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 2000/2000 [00:16<00:00, 123.02it/s]\n",
      "/tmp/ipykernel_2621543/85556528.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  custom_mlp.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1990/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 1990: 62.39%\n",
      "Classification Report at Epoch 1990:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n",
      "Epoch 2000/2000, Loss: 0.0000\n",
      "Test Accuracy at Epoch 2000: 62.39%\n",
      "Classification Report at Epoch 2000:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.71      0.54      0.61        65\n",
      "non_infringement       0.56      0.73      0.63        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.64      0.63      0.62       117\n",
      "    weighted avg       0.65      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 62.39%\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 256 \n",
    "print(f\"Training MLP model with input_dim={input_dim} and hidden_dim={hidden_dim}\")\n",
    "\n",
    "custom_mlp, losses, best_accuracy = train_model(X_train, y_train, X_test, y_test, input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/models/train_input_reference_last_layer_PCA3_10.pth'.\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to '{filepath}'.\")\n",
    "\n",
    "save_checkpoint(custom_mlp, torch.optim.Adam(custom_mlp.parameters()), len(losses), losses[-1], checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.57      0.63        65\n",
      "non_infringement       0.56      0.69      0.62        52\n",
      "\n",
      "        accuracy                           0.62       117\n",
      "       macro avg       0.63      0.63      0.62       117\n",
      "    weighted avg       0.64      0.62      0.62       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2621543/2137335780.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred_final = (torch.sigmoid(torch.tensor(custom_mlp(torch.tensor(X_test, dtype=torch.float32)))) > 0.5).float().numpy()\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = (torch.sigmoid(torch.tensor(custom_mlp(torch.tensor(X_test, dtype=torch.float32)))) > 0.5).float().numpy()\n",
    "print(classification_report(y_test, y_pred_final, target_names=[\"infringement\", \"non_infringement\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
