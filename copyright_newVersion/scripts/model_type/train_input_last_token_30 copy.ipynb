{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guangwei/miniconda3/envs/zdh/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,4,5,6,7\"\n",
    "\n",
    "# Variables\n",
    "model_name = 'meta-llama/Llama-3.1-70B'\n",
    "non_infringement_file = '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_test.non_infringement.json'\n",
    "infringement_file = '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_test.infringement.json'\n",
    "checkpoint_file = '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/models/train_input_last_token.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CustumMLP for internal states train\n",
    "class CustomMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(CustomMLP, self).__init__()\n",
    "        self.down = nn.Linear(input_dim, hidden_dim)\n",
    "        self.gate = nn.Linear(input_dim, hidden_dim)\n",
    "        self.up = nn.Linear(hidden_dim, 1)\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        down_output = self.down(x)\n",
    "        gate_output = self.gate(x)\n",
    "        gated_output = down_output * self.activation(gate_output)\n",
    "        return self.up(gated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(texts, model, tokenizer, batch_size=8):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # 将模型移动到 GPU\n",
    "    # model = nn.DataParallel(model)  # 使用 DataParallel 包装模型，支持多卡\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4, 5, 6, 7])  # 使用多卡进行数据并行\n",
    "\n",
    "    hidden_states = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing data batches\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}  # 将数据移动到 GPU\n",
    "\n",
    "        with torch.no_grad():  # 在推理时关闭梯度计算\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # 获取最后一层的最后一个 token 的隐藏状态\n",
    "        last_layer_hidden_states = outputs.hidden_states[-1]  # 最后一层的隐藏状态\n",
    "        last_token_hidden_states = last_layer_hidden_states[:, -1, :]  # 取最后一个 token\n",
    "        hidden_states.append(last_token_hidden_states.cpu().numpy())  # 将结果转移到 CPU，并转换为 numpy 数组\n",
    "\n",
    "    return np.vstack(hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用多个 GPU 进行推理\n",
    "def main(texts, model, tokenizer):\n",
    "    # 将模型移动到 CUDA 设备，并封装到 DataParallel 中\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model = nn.DataParallel(model)  # 使用 DataParallel 进行多卡支持\n",
    "\n",
    "    # 运行提取隐藏状态的函数\n",
    "    return extract_hidden_states(texts, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lode data for infringement & non infringement\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    non_infringement_outputs = [entry['input'] for entry in non_infringement_json_data]\n",
    "    y_non_infringement = [1] * len(non_infringement_outputs)\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    infringement_outputs = [entry['input'] for entry in infringement_json_data]\n",
    "    y_infringement = [0] * len(infringement_outputs)\n",
    "\n",
    "    return non_infringement_outputs, y_non_infringement, infringement_outputs, y_infringement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "# Train for best model\n",
    "def train_model(X_train, y_train, X_test, y_test, input_dim, hidden_dim, epochs=2000, lr=0.001, checkpoint_path=checkpoint_file):\n",
    "    custom_mlp = CustomMLP(input_dim, hidden_dim)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(custom_mlp.parameters(), lr=lr)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    best_accuracy = -float('inf')  # Initialize the best accuracy to negative infinity\n",
    "    best_f1 = -float('inf')  # Initialize the best F1-score to negative infinity\n",
    "    best_model_state = None  # Store the state of the best model\n",
    "    best_epoch = 0  # Track the epoch with the best accuracy\n",
    "    losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "        custom_mlp.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = custom_mlp(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "            custom_mlp.eval()\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                y_pred_logits = custom_mlp(X_test_tensor)\n",
    "                y_pred = (torch.sigmoid(y_pred_logits) > 0.5).float().numpy()\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)  # Calculate F1-score\n",
    "            print(f\"Test Accuracy at Epoch {epoch + 1}: {accuracy * 100:.2f}%\")\n",
    "            print(f\"Test F1-score at Epoch {epoch + 1}: {f1:.4f}\")\n",
    "            \n",
    "            report = classification_report(y_test, y_pred, target_names=[\"infringement\", \"non_infringement\"])\n",
    "            print(f\"Classification Report at Epoch {epoch + 1}:\\n{report}\")\n",
    "\n",
    "            # Check if the current model is the best based on F1-score\n",
    "            if f1 > best_f1:\n",
    "                best_accuracy = accuracy\n",
    "                best_f1 = f1\n",
    "                best_model_state = custom_mlp.state_dict()\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(best_model_state, checkpoint_path)\n",
    "                print(f\"New best model saved with F1-score {best_f1:.4f} at epoch {best_epoch}\")\n",
    "                print(f\"Best Classification Report at Epoch {best_epoch}:\\n{report}\")\n",
    "\n",
    "    # Load the best model state\n",
    "    custom_mlp.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Best Model was saved at epoch {best_epoch} with F1-score {best_f1:.4f} and accuracy {best_accuracy * 100:.2f}%\")\n",
    "    return custom_mlp, losses, best_accuracy, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guangwei/miniconda3/envs/zdh/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:17<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "non_infringement_outputs, y_non_infringement, infringement_outputs, y_infringement = load_data(non_infringement_file, infringement_file)\n",
    "\n",
    "y_non_infringement = np.array(y_non_infringement)\n",
    "y_infringement = np.array(y_infringement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 60.75 MiB is free. Including non-PyTorch memory, this process has 79.07 GiB memory in use. Of the allocated memory 78.67 GiB is allocated by PyTorch, and 564.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_non_infringement \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_infringement_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X_infringement \u001b[38;5;241m=\u001b[39m main(infringement_outputs, model, tokenizer)\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(texts, model, tokenizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(texts, model, tokenizer):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 将模型移动到 CUDA 设备，并封装到 DataParallel 中\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDataParallel(model)  \u001b[38;5;66;03m# 使用 DataParallel 进行多卡支持\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# 运行提取隐藏状态的函数\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/transformers/modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3156\u001b[0m         )\n\u001b[0;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/zdh/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 60.75 MiB is free. Including non-PyTorch memory, this process has 79.07 GiB memory in use. Of the allocated memory 78.67 GiB is allocated by PyTorch, and 564.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_non_infringement = main(non_infringement_outputs, model, tokenizer)\n",
    "X_infringement = main(infringement_outputs, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into training and test sets.\n"
     ]
    }
   ],
   "source": [
    "split_index_non_infringement = int(0.8 * len(X_non_infringement))\n",
    "X_non_infringement_train = X_non_infringement[:split_index_non_infringement]\n",
    "X_non_infringement_test = X_non_infringement[split_index_non_infringement:]\n",
    "y_non_infringement_train = y_non_infringement[:split_index_non_infringement]\n",
    "y_non_infringement_test = y_non_infringement[split_index_non_infringement:]\n",
    "\n",
    "split_index_infringement = int(0.8 * len(X_infringement))\n",
    "X_infringement_train = X_infringement[:split_index_infringement]\n",
    "X_infringement_test = X_infringement[split_index_infringement:]\n",
    "y_infringement_train = y_infringement[:split_index_infringement]\n",
    "y_infringement_test = y_infringement[split_index_infringement:]\n",
    "\n",
    "X_train = np.vstack((X_non_infringement_train, X_infringement_train))\n",
    "X_test = np.vstack((X_non_infringement_test, X_infringement_test))\n",
    "y_train = np.concatenate((y_non_infringement_train, y_infringement_train))\n",
    "y_test = np.concatenate((y_non_infringement_test, y_infringement_test))\n",
    "\n",
    "print(\"Data successfully split into training and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|          | 20/2000 [00:00<00:41, 47.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000, Loss: 1.0688\n",
      "Test Accuracy at Epoch 10: 49.68%\n",
      "Test F1-score at Epoch 10: 0.1780\n",
      "Classification Report at Epoch 10:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.48      0.95      0.64       146\n",
      "non_infringement       0.68      0.10      0.18       166\n",
      "\n",
      "        accuracy                           0.50       312\n",
      "       macro avg       0.58      0.52      0.41       312\n",
      "    weighted avg       0.59      0.50      0.39       312\n",
      "\n",
      "New best model saved with F1-score 0.1780 at epoch 10\n",
      "Best Classification Report at Epoch 10:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.48      0.95      0.64       146\n",
      "non_infringement       0.68      0.10      0.18       166\n",
      "\n",
      "        accuracy                           0.50       312\n",
      "       macro avg       0.58      0.52      0.41       312\n",
      "    weighted avg       0.59      0.50      0.39       312\n",
      "\n",
      "Epoch 20/2000, Loss: 0.5733\n",
      "Test Accuracy at Epoch 20: 59.62%\n",
      "Test F1-score at Epoch 20: 0.6986\n",
      "Classification Report at Epoch 20:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.27      0.39       146\n",
      "non_infringement       0.58      0.88      0.70       166\n",
      "\n",
      "        accuracy                           0.60       312\n",
      "       macro avg       0.62      0.58      0.54       312\n",
      "    weighted avg       0.62      0.60      0.55       312\n",
      "\n",
      "New best model saved with F1-score 0.6986 at epoch 20\n",
      "Best Classification Report at Epoch 20:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.27      0.39       146\n",
      "non_infringement       0.58      0.88      0.70       166\n",
      "\n",
      "        accuracy                           0.60       312\n",
      "       macro avg       0.62      0.58      0.54       312\n",
      "    weighted avg       0.62      0.60      0.55       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▏         | 40/2000 [00:00<00:28, 68.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/2000, Loss: 0.5685\n",
      "Test Accuracy at Epoch 30: 55.77%\n",
      "Test F1-score at Epoch 30: 0.6480\n",
      "Classification Report at Epoch 30:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.55      0.32      0.41       146\n",
      "non_infringement       0.56      0.77      0.65       166\n",
      "\n",
      "        accuracy                           0.56       312\n",
      "       macro avg       0.55      0.54      0.53       312\n",
      "    weighted avg       0.55      0.56      0.53       312\n",
      "\n",
      "Epoch 40/2000, Loss: 0.5599\n",
      "Test Accuracy at Epoch 40: 58.01%\n",
      "Test F1-score at Epoch 40: 0.6797\n",
      "Classification Report at Epoch 40:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.29      0.39       146\n",
      "non_infringement       0.57      0.84      0.68       166\n",
      "\n",
      "        accuracy                           0.58       312\n",
      "       macro avg       0.59      0.56      0.54       312\n",
      "    weighted avg       0.59      0.58      0.54       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   3%|▎         | 60/2000 [00:01<00:24, 78.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/2000, Loss: 0.5506\n",
      "Test Accuracy at Epoch 50: 57.05%\n",
      "Test F1-score at Epoch 50: 0.6582\n",
      "Classification Report at Epoch 50:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.57      0.34      0.42       146\n",
      "non_infringement       0.57      0.78      0.66       166\n",
      "\n",
      "        accuracy                           0.57       312\n",
      "       macro avg       0.57      0.56      0.54       312\n",
      "    weighted avg       0.57      0.57      0.55       312\n",
      "\n",
      "Epoch 60/2000, Loss: 0.5388\n",
      "Test Accuracy at Epoch 60: 58.65%\n",
      "Test F1-score at Epoch 60: 0.6427\n",
      "Classification Report at Epoch 60:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.57      0.46      0.51       146\n",
      "non_infringement       0.59      0.70      0.64       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.58      0.58      0.58       312\n",
      "    weighted avg       0.58      0.59      0.58       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   4%|▍         | 80/2000 [00:01<00:21, 87.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/2000, Loss: 0.5243\n",
      "Test Accuracy at Epoch 70: 59.62%\n",
      "Test F1-score at Epoch 70: 0.6379\n",
      "Classification Report at Epoch 70:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.58      0.51      0.54       146\n",
      "non_infringement       0.61      0.67      0.64       166\n",
      "\n",
      "        accuracy                           0.60       312\n",
      "       macro avg       0.59      0.59      0.59       312\n",
      "    weighted avg       0.59      0.60      0.59       312\n",
      "\n",
      "Epoch 80/2000, Loss: 0.5036\n",
      "Test Accuracy at Epoch 80: 64.42%\n",
      "Test F1-score at Epoch 80: 0.6667\n",
      "Classification Report at Epoch 80:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.62      0.62       146\n",
      "non_infringement       0.66      0.67      0.67       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.64      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   5%|▌         | 101/2000 [00:01<00:20, 94.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/2000, Loss: 0.4867\n",
      "Test Accuracy at Epoch 90: 64.42%\n",
      "Test F1-score at Epoch 90: 0.6783\n",
      "Classification Report at Epoch 90:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.58      0.60       146\n",
      "non_infringement       0.65      0.70      0.68       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.64      0.64      0.64       312\n",
      "\n",
      "Epoch 100/2000, Loss: 0.4749\n",
      "Test Accuracy at Epoch 100: 63.14%\n",
      "Test F1-score at Epoch 100: 0.6526\n",
      "Classification Report at Epoch 100:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.61      0.61       146\n",
      "non_infringement       0.65      0.65      0.65       166\n",
      "\n",
      "        accuracy                           0.63       312\n",
      "       macro avg       0.63      0.63      0.63       312\n",
      "    weighted avg       0.63      0.63      0.63       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   6%|▌         | 121/2000 [00:01<00:22, 83.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/2000, Loss: 0.5215\n",
      "Test Accuracy at Epoch 110: 61.54%\n",
      "Test F1-score at Epoch 110: 0.6178\n",
      "Classification Report at Epoch 110:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.58      0.65      0.61       146\n",
      "non_infringement       0.66      0.58      0.62       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.62      0.62      0.62       312\n",
      "    weighted avg       0.62      0.62      0.62       312\n",
      "\n",
      "Epoch 120/2000, Loss: 0.5075\n",
      "Test Accuracy at Epoch 120: 61.54%\n",
      "Test F1-score at Epoch 120: 0.6757\n",
      "Classification Report at Epoch 120:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.46      0.53       146\n",
      "non_infringement       0.61      0.75      0.68       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.62      0.61      0.60       312\n",
      "    weighted avg       0.62      0.62      0.61       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   7%|▋         | 140/2000 [00:01<00:22, 83.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/2000, Loss: 0.4972\n",
      "Test Accuracy at Epoch 130: 63.78%\n",
      "Test F1-score at Epoch 130: 0.6971\n",
      "Classification Report at Epoch 130:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.47      0.55       146\n",
      "non_infringement       0.63      0.78      0.70       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.63      0.62       312\n",
      "    weighted avg       0.64      0.64      0.63       312\n",
      "\n",
      "Epoch 140/2000, Loss: 0.4854\n",
      "Test Accuracy at Epoch 140: 62.18%\n",
      "Test F1-score at Epoch 140: 0.6629\n",
      "Classification Report at Epoch 140:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.53      0.57       146\n",
      "non_infringement       0.63      0.70      0.66       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.62      0.62      0.62       312\n",
      "    weighted avg       0.62      0.62      0.62       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   8%|▊         | 160/2000 [00:02<00:21, 87.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/2000, Loss: 0.4733\n",
      "Test Accuracy at Epoch 150: 64.74%\n",
      "Test F1-score at Epoch 150: 0.6746\n",
      "Classification Report at Epoch 150:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.60      0.62       146\n",
      "non_infringement       0.66      0.69      0.67       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.64      0.64       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 160/2000, Loss: 0.4602\n",
      "Test Accuracy at Epoch 160: 64.42%\n",
      "Test F1-score at Epoch 160: 0.6687\n",
      "Classification Report at Epoch 160:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.61      0.62       146\n",
      "non_infringement       0.66      0.67      0.67       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.64      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   9%|▉         | 180/2000 [00:02<00:19, 91.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/2000, Loss: 0.4466\n",
      "Test Accuracy at Epoch 170: 64.74%\n",
      "Test F1-score at Epoch 170: 0.6746\n",
      "Classification Report at Epoch 170:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.60      0.62       146\n",
      "non_infringement       0.66      0.69      0.67       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.64      0.64       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 180/2000, Loss: 0.4324\n",
      "Test Accuracy at Epoch 180: 65.38%\n",
      "Test F1-score at Epoch 180: 0.6824\n",
      "Classification Report at Epoch 180:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.60      0.62       146\n",
      "non_infringement       0.67      0.70      0.68       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|█         | 200/2000 [00:02<00:19, 92.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/2000, Loss: 0.4179\n",
      "Test Accuracy at Epoch 190: 62.82%\n",
      "Test F1-score at Epoch 190: 0.6463\n",
      "Classification Report at Epoch 190:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.62      0.61       146\n",
      "non_infringement       0.65      0.64      0.65       166\n",
      "\n",
      "        accuracy                           0.63       312\n",
      "       macro avg       0.63      0.63      0.63       312\n",
      "    weighted avg       0.63      0.63      0.63       312\n",
      "\n",
      "Epoch 200/2000, Loss: 0.4031\n",
      "Test Accuracy at Epoch 200: 64.74%\n",
      "Test F1-score at Epoch 200: 0.6687\n",
      "Classification Report at Epoch 200:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.62      0.62       146\n",
      "non_infringement       0.67      0.67      0.67       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 220/2000 [00:02<00:20, 87.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/2000, Loss: 0.3880\n",
      "Test Accuracy at Epoch 210: 64.74%\n",
      "Test F1-score at Epoch 210: 0.6626\n",
      "Classification Report at Epoch 210:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.64      0.63       146\n",
      "non_infringement       0.68      0.65      0.66       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 220/2000, Loss: 0.3720\n",
      "Test Accuracy at Epoch 220: 64.42%\n",
      "Test F1-score at Epoch 220: 0.6606\n",
      "Classification Report at Epoch 220:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.64      0.63       146\n",
      "non_infringement       0.67      0.65      0.66       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 239/2000 [00:03<00:19, 89.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/2000, Loss: 0.3568\n",
      "Test Accuracy at Epoch 230: 64.42%\n",
      "Test F1-score at Epoch 230: 0.6563\n",
      "Classification Report at Epoch 230:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.65      0.63       146\n",
      "non_infringement       0.68      0.64      0.66       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n",
      "Epoch 240/2000, Loss: 0.3421\n",
      "Test Accuracy at Epoch 240: 64.42%\n",
      "Test F1-score at Epoch 240: 0.6542\n",
      "Classification Report at Epoch 240:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.66      0.63       146\n",
      "non_infringement       0.68      0.63      0.65       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 267/2000 [00:03<00:19, 88.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/2000, Loss: 0.3293\n",
      "Test Accuracy at Epoch 250: 67.31%\n",
      "Test F1-score at Epoch 250: 0.6946\n",
      "Classification Report at Epoch 250:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.64      0.65       146\n",
      "non_infringement       0.69      0.70      0.69       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n",
      "Epoch 260/2000, Loss: 0.3774\n",
      "Test Accuracy at Epoch 260: 64.74%\n",
      "Test F1-score at Epoch 260: 0.6519\n",
      "Classification Report at Epoch 260:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.68      0.64       146\n",
      "non_infringement       0.69      0.62      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 286/2000 [00:03<00:19, 87.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/2000, Loss: 0.3202\n",
      "Test Accuracy at Epoch 270: 64.42%\n",
      "Test F1-score at Epoch 270: 0.6647\n",
      "Classification Report at Epoch 270:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.62      0.62       146\n",
      "non_infringement       0.67      0.66      0.66       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.64      0.64      0.64       312\n",
      "\n",
      "Epoch 280/2000, Loss: 0.3218\n",
      "Test Accuracy at Epoch 280: 65.71%\n",
      "Test F1-score at Epoch 280: 0.6559\n",
      "Classification Report at Epoch 280:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.70      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  15%|█▌        | 304/2000 [00:03<00:19, 86.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/2000, Loss: 0.3090\n",
      "Test Accuracy at Epoch 290: 63.46%\n",
      "Test F1-score at Epoch 290: 0.6438\n",
      "Classification Report at Epoch 290:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.65      0.62       146\n",
      "non_infringement       0.67      0.62      0.64       166\n",
      "\n",
      "        accuracy                           0.63       312\n",
      "       macro avg       0.64      0.64      0.63       312\n",
      "    weighted avg       0.64      0.63      0.63       312\n",
      "\n",
      "Epoch 300/2000, Loss: 0.2986\n",
      "Test Accuracy at Epoch 300: 64.42%\n",
      "Test F1-score at Epoch 300: 0.6542\n",
      "Classification Report at Epoch 300:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.66      0.63       146\n",
      "non_infringement       0.68      0.63      0.65       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|█▌        | 323/2000 [00:03<00:19, 87.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/2000, Loss: 0.2900\n",
      "Test Accuracy at Epoch 310: 64.74%\n",
      "Test F1-score at Epoch 310: 0.6474\n",
      "Classification Report at Epoch 310:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.69      0.65       146\n",
      "non_infringement       0.69      0.61      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 320/2000, Loss: 0.3376\n",
      "Test Accuracy at Epoch 320: 66.35%\n",
      "Test F1-score at Epoch 320: 0.6789\n",
      "Classification Report at Epoch 320:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.66      0.65       146\n",
      "non_infringement       0.69      0.67      0.68       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  17%|█▋        | 343/2000 [00:04<00:18, 90.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/2000, Loss: 0.3292\n",
      "Test Accuracy at Epoch 330: 66.35%\n",
      "Test F1-score at Epoch 330: 0.6580\n",
      "Classification Report at Epoch 330:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.73      0.67       146\n",
      "non_infringement       0.72      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 340/2000, Loss: 0.3078\n",
      "Test Accuracy at Epoch 340: 66.03%\n",
      "Test F1-score at Epoch 340: 0.6624\n",
      "Classification Report at Epoch 340:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.70      0.66       146\n",
      "non_infringement       0.70      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  18%|█▊        | 363/2000 [00:04<00:18, 90.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/2000, Loss: 0.2953\n",
      "Test Accuracy at Epoch 350: 64.74%\n",
      "Test F1-score at Epoch 350: 0.6541\n",
      "Classification Report at Epoch 350:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.67      0.64       146\n",
      "non_infringement       0.68      0.63      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 360/2000, Loss: 0.2876\n",
      "Test Accuracy at Epoch 360: 64.42%\n",
      "Test F1-score at Epoch 360: 0.6498\n",
      "Classification Report at Epoch 360:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.67      0.64       146\n",
      "non_infringement       0.68      0.62      0.65       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.65      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  19%|█▉        | 382/2000 [00:04<00:18, 86.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/2000, Loss: 0.2825\n",
      "Test Accuracy at Epoch 370: 66.03%\n",
      "Test F1-score at Epoch 370: 0.6603\n",
      "Classification Report at Epoch 370:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.62      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 380/2000, Loss: 0.3087\n",
      "Test Accuracy at Epoch 380: 66.03%\n",
      "Test F1-score at Epoch 380: 0.6748\n",
      "Classification Report at Epoch 380:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.66      0.64       146\n",
      "non_infringement       0.69      0.66      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|█▉        | 391/2000 [00:04<00:19, 82.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/2000, Loss: 0.2952\n",
      "Test Accuracy at Epoch 390: 66.35%\n",
      "Test F1-score at Epoch 390: 0.6557\n",
      "Classification Report at Epoch 390:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.73      0.67       146\n",
      "non_infringement       0.72      0.60      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 400/2000 [00:04<00:25, 63.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/2000, Loss: 0.3033\n",
      "Test Accuracy at Epoch 400: 65.38%\n",
      "Test F1-score at Epoch 400: 0.6582\n",
      "Classification Report at Epoch 400:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.68      0.65       146\n",
      "non_infringement       0.69      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  21%|██        | 420/2000 [00:06<01:18, 20.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/2000, Loss: 0.2922\n",
      "Test Accuracy at Epoch 410: 66.03%\n",
      "Test F1-score at Epoch 410: 0.6624\n",
      "Classification Report at Epoch 410:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.70      0.66       146\n",
      "non_infringement       0.70      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 420/2000, Loss: 0.2811\n",
      "Test Accuracy at Epoch 420: 66.03%\n",
      "Test F1-score at Epoch 420: 0.6581\n",
      "Classification Report at Epoch 420:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|██▏       | 436/2000 [00:07<00:49, 31.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/2000, Loss: 0.2891\n",
      "Test Accuracy at Epoch 430: 64.74%\n",
      "Test F1-score at Epoch 430: 0.6541\n",
      "Classification Report at Epoch 430:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.67      0.64       146\n",
      "non_infringement       0.68      0.63      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 440/2000, Loss: 0.2735\n",
      "Test Accuracy at Epoch 440: 65.06%\n",
      "Test F1-score at Epoch 440: 0.6540\n",
      "Classification Report at Epoch 440:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.68      0.65       146\n",
      "non_infringement       0.69      0.62      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  23%|██▎       | 463/2000 [00:07<00:26, 57.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/2000, Loss: 0.2679\n",
      "Test Accuracy at Epoch 450: 64.42%\n",
      "Test F1-score at Epoch 450: 0.6542\n",
      "Classification Report at Epoch 450:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.66      0.63       146\n",
      "non_infringement       0.68      0.63      0.65       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n",
      "Epoch 460/2000, Loss: 0.2633\n",
      "Test Accuracy at Epoch 460: 65.38%\n",
      "Test F1-score at Epoch 460: 0.6582\n",
      "Classification Report at Epoch 460:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.68      0.65       146\n",
      "non_infringement       0.69      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  24%|██▍       | 479/2000 [00:07<00:23, 64.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/2000, Loss: 0.2607\n",
      "Test Accuracy at Epoch 470: 66.99%\n",
      "Test F1-score at Epoch 470: 0.6667\n",
      "Classification Report at Epoch 470:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.73      0.67       146\n",
      "non_infringement       0.72      0.62      0.67       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n",
      "Epoch 480/2000, Loss: 0.2709\n",
      "Test Accuracy at Epoch 480: 65.38%\n",
      "Test F1-score at Epoch 480: 0.6604\n",
      "Classification Report at Epoch 480:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.68      0.65       146\n",
      "non_infringement       0.69      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  25%|██▌       | 507/2000 [00:07<00:19, 78.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/2000, Loss: 0.2843\n",
      "Test Accuracy at Epoch 490: 65.71%\n",
      "Test F1-score at Epoch 490: 0.6625\n",
      "Classification Report at Epoch 490:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.68      0.65       146\n",
      "non_infringement       0.70      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 500/2000, Loss: 0.2662\n",
      "Test Accuracy at Epoch 500: 65.71%\n",
      "Test F1-score at Epoch 500: 0.6515\n",
      "Classification Report at Epoch 500:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.72      0.66       146\n",
      "non_infringement       0.71      0.60      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  26%|██▌       | 524/2000 [00:08<00:19, 76.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 510/2000, Loss: 0.2780\n",
      "Test Accuracy at Epoch 510: 62.50%\n",
      "Test F1-score at Epoch 510: 0.6286\n",
      "Classification Report at Epoch 510:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.59      0.66      0.62       146\n",
      "non_infringement       0.66      0.60      0.63       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.63      0.63      0.62       312\n",
      "    weighted avg       0.63      0.62      0.63       312\n",
      "\n",
      "Epoch 520/2000, Loss: 0.2718\n",
      "Test Accuracy at Epoch 520: 65.06%\n",
      "Test F1-score at Epoch 520: 0.6403\n",
      "Classification Report at Epoch 520:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.66       146\n",
      "non_infringement       0.71      0.58      0.64       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  27%|██▋       | 543/2000 [00:08<00:17, 82.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/2000, Loss: 0.2500\n",
      "Test Accuracy at Epoch 530: 66.67%\n",
      "Test F1-score at Epoch 530: 0.6645\n",
      "Classification Report at Epoch 530:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.72      0.67       146\n",
      "non_infringement       0.72      0.62      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n",
      "Epoch 540/2000, Loss: 0.2835\n",
      "Test Accuracy at Epoch 540: 67.31%\n",
      "Test F1-score at Epoch 540: 0.6667\n",
      "Classification Report at Epoch 540:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.74      0.68       146\n",
      "non_infringement       0.73      0.61      0.67       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.68      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  28%|██▊       | 552/2000 [00:08<00:18, 77.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/2000, Loss: 0.2477\n",
      "Test Accuracy at Epoch 550: 66.67%\n",
      "Test F1-score at Epoch 550: 0.6601\n",
      "Classification Report at Epoch 550:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.73      0.67       146\n",
      "non_infringement       0.72      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  28%|██▊       | 568/2000 [00:09<00:34, 41.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/2000, Loss: 0.2493\n",
      "Test Accuracy at Epoch 560: 64.42%\n",
      "Test F1-score at Epoch 560: 0.6431\n",
      "Classification Report at Epoch 560:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.69      0.65       146\n",
      "non_infringement       0.69      0.60      0.64       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.65      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n",
      "Epoch 570/2000, Loss: 0.2405\n",
      "Test Accuracy at Epoch 570: 65.06%\n",
      "Test F1-score at Epoch 570: 0.6403\n",
      "Classification Report at Epoch 570:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.66       146\n",
      "non_infringement       0.71      0.58      0.64       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|██▉       | 595/2000 [00:09<00:21, 64.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/2000, Loss: 0.2811\n",
      "Test Accuracy at Epoch 580: 66.03%\n",
      "Test F1-score at Epoch 580: 0.6319\n",
      "Classification Report at Epoch 580:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.79      0.68       146\n",
      "non_infringement       0.75      0.55      0.63       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.68      0.67      0.66       312\n",
      "    weighted avg       0.68      0.66      0.66       312\n",
      "\n",
      "Epoch 590/2000, Loss: 0.2911\n",
      "Test Accuracy at Epoch 590: 64.74%\n",
      "Test F1-score at Epoch 590: 0.6452\n",
      "Classification Report at Epoch 590:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.70      0.65       146\n",
      "non_infringement       0.69      0.60      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  31%|███       | 614/2000 [00:09<00:18, 74.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/2000, Loss: 0.2709\n",
      "Test Accuracy at Epoch 600: 65.71%\n",
      "Test F1-score at Epoch 600: 0.6469\n",
      "Classification Report at Epoch 600:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.67       146\n",
      "non_infringement       0.72      0.59      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 610/2000, Loss: 0.2539\n",
      "Test Accuracy at Epoch 610: 65.38%\n",
      "Test F1-score at Epoch 610: 0.6424\n",
      "Classification Report at Epoch 610:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.66       146\n",
      "non_infringement       0.71      0.58      0.64       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  32%|███▏      | 632/2000 [00:09<00:17, 77.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/2000, Loss: 0.2442\n",
      "Test Accuracy at Epoch 620: 65.38%\n",
      "Test F1-score at Epoch 620: 0.6424\n",
      "Classification Report at Epoch 620:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.66       146\n",
      "non_infringement       0.71      0.58      0.64       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n",
      "Epoch 630/2000, Loss: 0.2411\n",
      "Test Accuracy at Epoch 630: 65.38%\n",
      "Test F1-score at Epoch 630: 0.6424\n",
      "Classification Report at Epoch 630:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.66       146\n",
      "non_infringement       0.71      0.58      0.64       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  33%|███▎      | 652/2000 [00:10<00:15, 85.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640/2000, Loss: 0.2366\n",
      "Test Accuracy at Epoch 640: 64.42%\n",
      "Test F1-score at Epoch 640: 0.6312\n",
      "Classification Report at Epoch 640:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.73      0.66       146\n",
      "non_infringement       0.70      0.57      0.63       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.65      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n",
      "Epoch 650/2000, Loss: 0.2333\n",
      "Test Accuracy at Epoch 650: 64.42%\n",
      "Test F1-score at Epoch 650: 0.6312\n",
      "Classification Report at Epoch 650:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.73      0.66       146\n",
      "non_infringement       0.70      0.57      0.63       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.65      0.65      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  34%|███▎      | 670/2000 [00:10<00:18, 73.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/2000, Loss: 0.2332\n",
      "Test Accuracy at Epoch 660: 65.71%\n",
      "Test F1-score at Epoch 660: 0.6421\n",
      "Classification Report at Epoch 660:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.75      0.67       146\n",
      "non_infringement       0.72      0.58      0.64       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 670/2000, Loss: 0.4982\n",
      "Test Accuracy at Epoch 670: 66.35%\n",
      "Test F1-score at Epoch 670: 0.6367\n",
      "Classification Report at Epoch 670:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.79      0.69       146\n",
      "non_infringement       0.75      0.55      0.64       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.68      0.67      0.66       312\n",
      "    weighted avg       0.68      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  34%|███▍      | 685/2000 [00:10<00:26, 48.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/2000, Loss: 0.3317\n",
      "Test Accuracy at Epoch 680: 65.71%\n",
      "Test F1-score at Epoch 680: 0.6559\n",
      "Classification Report at Epoch 680:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.70      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  35%|███▌      | 700/2000 [00:11<00:23, 54.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690/2000, Loss: 0.3240\n",
      "Test Accuracy at Epoch 690: 65.71%\n",
      "Test F1-score at Epoch 690: 0.6581\n",
      "Classification Report at Epoch 690:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.70      0.66       146\n",
      "non_infringement       0.70      0.62      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 700/2000, Loss: 0.3011\n",
      "Test Accuracy at Epoch 700: 66.35%\n",
      "Test F1-score at Epoch 700: 0.6645\n",
      "Classification Report at Epoch 700:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  36%|███▌      | 710/2000 [00:11<00:20, 64.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/2000, Loss: 0.2839\n",
      "Test Accuracy at Epoch 710: 64.74%\n",
      "Test F1-score at Epoch 710: 0.6497\n",
      "Classification Report at Epoch 710:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.68      0.65       146\n",
      "non_infringement       0.69      0.61      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  37%|███▋      | 731/2000 [00:11<00:30, 41.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/2000, Loss: 0.2924\n",
      "Test Accuracy at Epoch 720: 66.99%\n",
      "Test F1-score at Epoch 720: 0.6508\n",
      "Classification Report at Epoch 720:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.77      0.69       146\n",
      "non_infringement       0.74      0.58      0.65       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.68      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n",
      "Epoch 730/2000, Loss: 0.2858\n",
      "Test Accuracy at Epoch 730: 65.71%\n",
      "Test F1-score at Epoch 730: 0.6537\n",
      "Classification Report at Epoch 730:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.61      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  38%|███▊      | 750/2000 [00:12<00:21, 58.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/2000, Loss: 0.2765\n",
      "Test Accuracy at Epoch 740: 65.71%\n",
      "Test F1-score at Epoch 740: 0.6581\n",
      "Classification Report at Epoch 740:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.70      0.66       146\n",
      "non_infringement       0.70      0.62      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 750/2000, Loss: 0.3147\n",
      "Test Accuracy at Epoch 750: 65.38%\n",
      "Test F1-score at Epoch 750: 0.6646\n",
      "Classification Report at Epoch 750:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.66      0.64       146\n",
      "non_infringement       0.69      0.64      0.66       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  39%|███▉      | 777/2000 [00:12<00:16, 74.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/2000, Loss: 0.4212\n",
      "Test Accuracy at Epoch 760: 65.71%\n",
      "Test F1-score at Epoch 760: 0.6603\n",
      "Classification Report at Epoch 760:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.69      0.65       146\n",
      "non_infringement       0.70      0.63      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 770/2000, Loss: 0.5759\n",
      "Test Accuracy at Epoch 770: 57.05%\n",
      "Test F1-score at Epoch 770: 0.6667\n",
      "Classification Report at Epoch 770:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.58      0.30      0.40       146\n",
      "non_infringement       0.57      0.81      0.67       166\n",
      "\n",
      "        accuracy                           0.57       312\n",
      "       macro avg       0.57      0.55      0.53       312\n",
      "    weighted avg       0.57      0.57      0.54       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|███▉      | 795/2000 [00:12<00:15, 78.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/2000, Loss: 0.3762\n",
      "Test Accuracy at Epoch 780: 66.03%\n",
      "Test F1-score at Epoch 780: 0.6581\n",
      "Classification Report at Epoch 780:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 790/2000, Loss: 0.4174\n",
      "Test Accuracy at Epoch 790: 63.46%\n",
      "Test F1-score at Epoch 790: 0.6323\n",
      "Classification Report at Epoch 790:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.68      0.64       146\n",
      "non_infringement       0.68      0.59      0.63       166\n",
      "\n",
      "        accuracy                           0.63       312\n",
      "       macro avg       0.64      0.64      0.63       312\n",
      "    weighted avg       0.64      0.63      0.63       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  41%|████      | 813/2000 [00:12<00:15, 78.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/2000, Loss: 0.3126\n",
      "Test Accuracy at Epoch 800: 68.27%\n",
      "Test F1-score at Epoch 800: 0.6857\n",
      "Classification Report at Epoch 800:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.72      0.68       146\n",
      "non_infringement       0.72      0.65      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n",
      "Epoch 810/2000, Loss: 0.3114\n",
      "Test Accuracy at Epoch 810: 65.38%\n",
      "Test F1-score at Epoch 810: 0.6327\n",
      "Classification Report at Epoch 810:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.76      0.67       146\n",
      "non_infringement       0.73      0.56      0.63       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.67      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████▏     | 831/2000 [00:13<00:14, 81.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/2000, Loss: 0.3040\n",
      "Test Accuracy at Epoch 820: 66.03%\n",
      "Test F1-score at Epoch 820: 0.6667\n",
      "Classification Report at Epoch 820:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.68      0.65       146\n",
      "non_infringement       0.70      0.64      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 830/2000, Loss: 0.2881\n",
      "Test Accuracy at Epoch 830: 65.71%\n",
      "Test F1-score at Epoch 830: 0.6537\n",
      "Classification Report at Epoch 830:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.61      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████▎     | 851/2000 [00:13<00:13, 87.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/2000, Loss: 0.2864\n",
      "Test Accuracy at Epoch 840: 66.99%\n",
      "Test F1-score at Epoch 840: 0.6667\n",
      "Classification Report at Epoch 840:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.73      0.67       146\n",
      "non_infringement       0.72      0.62      0.67       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n",
      "Epoch 850/2000, Loss: 0.2834\n",
      "Test Accuracy at Epoch 850: 65.71%\n",
      "Test F1-score at Epoch 850: 0.6687\n",
      "Classification Report at Epoch 850:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.66      0.64       146\n",
      "non_infringement       0.69      0.65      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  44%|████▎     | 870/2000 [00:13<00:12, 90.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860/2000, Loss: 0.2934\n",
      "Test Accuracy at Epoch 860: 66.99%\n",
      "Test F1-score at Epoch 860: 0.6555\n",
      "Classification Report at Epoch 860:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.76      0.68       146\n",
      "non_infringement       0.74      0.59      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.68      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n",
      "Epoch 870/2000, Loss: 0.2745\n",
      "Test Accuracy at Epoch 870: 66.35%\n",
      "Test F1-score at Epoch 870: 0.6729\n",
      "Classification Report at Epoch 870:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.68      0.65       146\n",
      "non_infringement       0.70      0.65      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  44%|████▍     | 889/2000 [00:13<00:14, 75.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/2000, Loss: 0.2920\n",
      "Test Accuracy at Epoch 880: 66.03%\n",
      "Test F1-score at Epoch 880: 0.6419\n",
      "Classification Report at Epoch 880:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.76      0.68       146\n",
      "non_infringement       0.73      0.57      0.64       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 890/2000, Loss: 0.2775\n",
      "Test Accuracy at Epoch 890: 66.99%\n",
      "Test F1-score at Epoch 890: 0.6555\n",
      "Classification Report at Epoch 890:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.76      0.68       146\n",
      "non_infringement       0.74      0.59      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.68      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  46%|████▌     | 911/2000 [00:14<00:24, 43.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/2000, Loss: 0.2715\n",
      "Test Accuracy at Epoch 900: 66.67%\n",
      "Test F1-score at Epoch 900: 0.6750\n",
      "Classification Report at Epoch 900:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.68      0.66       146\n",
      "non_infringement       0.70      0.65      0.68       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n",
      "Epoch 910/2000, Loss: 0.2685\n",
      "Test Accuracy at Epoch 910: 68.27%\n",
      "Test F1-score at Epoch 910: 0.6817\n",
      "Classification Report at Epoch 910:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.68       146\n",
      "non_infringement       0.73      0.64      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.69      0.69      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  46%|████▋     | 929/2000 [00:14<00:17, 60.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 920/2000, Loss: 0.5124\n",
      "Test Accuracy at Epoch 920: 65.71%\n",
      "Test F1-score at Epoch 920: 0.6348\n",
      "Classification Report at Epoch 920:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.77      0.68       146\n",
      "non_infringement       0.73      0.56      0.63       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.65       312\n",
      "\n",
      "Epoch 930/2000, Loss: 0.3107\n",
      "Test Accuracy at Epoch 930: 66.03%\n",
      "Test F1-score at Epoch 930: 0.6467\n",
      "Classification Report at Epoch 930:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.75      0.67       146\n",
      "non_infringement       0.72      0.58      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  48%|████▊     | 957/2000 [00:15<00:13, 74.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/2000, Loss: 0.2762\n",
      "Test Accuracy at Epoch 940: 64.10%\n",
      "Test F1-score at Epoch 940: 0.6387\n",
      "Classification Report at Epoch 940:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.69      0.64       146\n",
      "non_infringement       0.69      0.60      0.64       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.64      0.64       312\n",
      "    weighted avg       0.65      0.64      0.64       312\n",
      "\n",
      "Epoch 950/2000, Loss: 0.2710\n",
      "Test Accuracy at Epoch 950: 65.38%\n",
      "Test F1-score at Epoch 950: 0.6516\n",
      "Classification Report at Epoch 950:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.71      0.66       146\n",
      "non_infringement       0.70      0.61      0.65       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  49%|████▉     | 977/2000 [00:15<00:12, 84.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/2000, Loss: 0.2631\n",
      "Test Accuracy at Epoch 960: 66.03%\n",
      "Test F1-score at Epoch 960: 0.6513\n",
      "Classification Report at Epoch 960:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.67       146\n",
      "non_infringement       0.72      0.60      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 970/2000, Loss: 0.2636\n",
      "Test Accuracy at Epoch 970: 64.74%\n",
      "Test F1-score at Epoch 970: 0.6309\n",
      "Classification Report at Epoch 970:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.74      0.66       146\n",
      "non_infringement       0.71      0.57      0.63       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.65      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  49%|████▉     | 987/2000 [00:15<00:11, 87.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980/2000, Loss: 0.2667\n",
      "Test Accuracy at Epoch 980: 67.63%\n",
      "Test F1-score at Epoch 980: 0.6892\n",
      "Classification Report at Epoch 980:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.68      0.66       146\n",
      "non_infringement       0.70      0.67      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n",
      "Epoch 990/2000, Loss: 0.4063\n",
      "Test Accuracy at Epoch 990: 63.14%\n",
      "Test F1-score at Epoch 990: 0.6667\n",
      "Classification Report at Epoch 990:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.56      0.59       146\n",
      "non_infringement       0.64      0.69      0.67       166\n",
      "\n",
      "        accuracy                           0.63       312\n",
      "       macro avg       0.63      0.63      0.63       312\n",
      "    weighted avg       0.63      0.63      0.63       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 1006/2000 [00:15<00:12, 78.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/2000, Loss: 0.3006\n",
      "Test Accuracy at Epoch 1000: 64.74%\n",
      "Test F1-score at Epoch 1000: 0.6233\n",
      "Classification Report at Epoch 1000:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.76      0.67       146\n",
      "non_infringement       0.72      0.55      0.62       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.65      0.65       312\n",
      "    weighted avg       0.66      0.65      0.64       312\n",
      "\n",
      "Epoch 1010/2000, Loss: 0.2897\n",
      "Test Accuracy at Epoch 1010: 65.06%\n",
      "Test F1-score at Epoch 1010: 0.6646\n",
      "Classification Report at Epoch 1010:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.65      0.64       146\n",
      "non_infringement       0.68      0.65      0.66       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  52%|█████▏    | 1033/2000 [00:16<00:11, 83.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020/2000, Loss: 0.2726\n",
      "Test Accuracy at Epoch 1020: 67.63%\n",
      "Test F1-score at Epoch 1020: 0.6645\n",
      "Classification Report at Epoch 1020:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.76      0.69       146\n",
      "non_infringement       0.74      0.60      0.66       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n",
      "Epoch 1030/2000, Loss: 0.2660\n",
      "Test Accuracy at Epoch 1030: 66.99%\n",
      "Test F1-score at Epoch 1030: 0.6623\n",
      "Classification Report at Epoch 1030:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.74      0.68       146\n",
      "non_infringement       0.73      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.67      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|█████▎    | 1051/2000 [00:16<00:11, 82.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2000, Loss: 0.2603\n",
      "Test Accuracy at Epoch 1040: 67.95%\n",
      "Test F1-score at Epoch 1040: 0.6774\n",
      "Classification Report at Epoch 1040:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.68       146\n",
      "non_infringement       0.73      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n",
      "Epoch 1050/2000, Loss: 0.2571\n",
      "Test Accuracy at Epoch 1050: 68.59%\n",
      "Test F1-score at Epoch 1050: 0.6918\n",
      "Classification Report at Epoch 1050:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.71      0.68       146\n",
      "non_infringement       0.72      0.66      0.69       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|█████▎    | 1068/2000 [00:16<00:16, 57.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1060/2000, Loss: 0.2549\n",
      "Test Accuracy at Epoch 1060: 68.59%\n",
      "Test F1-score at Epoch 1060: 0.6918\n",
      "Classification Report at Epoch 1060:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.71      0.68       146\n",
      "non_infringement       0.72      0.66      0.69       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1070/2000, Loss: 0.2525\n",
      "Test Accuracy at Epoch 1070: 67.95%\n",
      "Test F1-score at Epoch 1070: 0.6774\n",
      "Classification Report at Epoch 1070:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.68       146\n",
      "non_infringement       0.73      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  55%|█████▍    | 1094/2000 [00:17<00:23, 38.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1080/2000, Loss: 0.2794\n",
      "Test Accuracy at Epoch 1080: 67.31%\n",
      "Test F1-score at Epoch 1080: 0.6577\n",
      "Classification Report at Epoch 1080:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.77      0.69       146\n",
      "non_infringement       0.74      0.59      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.68      0.67       312\n",
      "    weighted avg       0.69      0.67      0.67       312\n",
      "\n",
      "Epoch 1090/2000, Loss: 0.4481\n",
      "Test Accuracy at Epoch 1090: 69.55%\n",
      "Test F1-score at Epoch 1090: 0.7147\n",
      "Classification Report at Epoch 1090:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.68      0.67      0.67       146\n",
      "non_infringement       0.71      0.72      0.71       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n",
      "New best model saved with F1-score 0.7147 at epoch 1090\n",
      "Best Classification Report at Epoch 1090:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.68      0.67      0.67       146\n",
      "non_infringement       0.71      0.72      0.71       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  56%|█████▌    | 1111/2000 [00:17<00:16, 52.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1100/2000, Loss: 0.4874\n",
      "Test Accuracy at Epoch 1100: 63.78%\n",
      "Test F1-score at Epoch 1100: 0.6781\n",
      "Classification Report at Epoch 1100:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.55      0.59       146\n",
      "non_infringement       0.64      0.72      0.68       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.63      0.63       312\n",
      "    weighted avg       0.64      0.64      0.64       312\n",
      "\n",
      "Epoch 1110/2000, Loss: 0.3679\n",
      "Test Accuracy at Epoch 1110: 65.06%\n",
      "Test F1-score at Epoch 1110: 0.6280\n",
      "Classification Report at Epoch 1110:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.76      0.67       146\n",
      "non_infringement       0.72      0.55      0.63       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.66      0.65       312\n",
      "    weighted avg       0.67      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  57%|█████▋    | 1133/2000 [00:18<00:11, 73.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1120/2000, Loss: 0.3458\n",
      "Test Accuracy at Epoch 1120: 67.95%\n",
      "Test F1-score at Epoch 1120: 0.6855\n",
      "Classification Report at Epoch 1120:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.71      0.67       146\n",
      "non_infringement       0.72      0.66      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n",
      "Epoch 1130/2000, Loss: 0.3038\n",
      "Test Accuracy at Epoch 1130: 66.99%\n",
      "Test F1-score at Epoch 1130: 0.6730\n",
      "Classification Report at Epoch 1130:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.71      0.67       146\n",
      "non_infringement       0.71      0.64      0.67       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n",
      "Epoch 1140/2000, Loss: 0.2880\n",
      "Test Accuracy at Epoch 1140: 68.91%\n",
      "Test F1-score at Epoch 1140: 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  58%|█████▊    | 1155/2000 [00:18<00:09, 86.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report at Epoch 1140:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.66      0.67       146\n",
      "non_infringement       0.71      0.71      0.71       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1150/2000, Loss: 0.2792\n",
      "Test Accuracy at Epoch 1150: 67.31%\n",
      "Test F1-score at Epoch 1150: 0.6832\n",
      "Classification Report at Epoch 1150:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.68      0.66       146\n",
      "non_infringement       0.71      0.66      0.68       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n",
      "Epoch 1160/2000, Loss: 0.2718\n",
      "Test Accuracy at Epoch 1160: 67.95%\n",
      "Test F1-score at Epoch 1160: 0.6914\n",
      "Classification Report at Epoch 1160:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.68      0.67       146\n",
      "non_infringement       0.71      0.67      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  59%|█████▉    | 1175/2000 [00:18<00:10, 81.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1170/2000, Loss: 0.2698\n",
      "Test Accuracy at Epoch 1170: 67.31%\n",
      "Test F1-score at Epoch 1170: 0.6752\n",
      "Classification Report at Epoch 1170:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.71      0.67       146\n",
      "non_infringement       0.72      0.64      0.68       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.68      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n",
      "Epoch 1180/2000, Loss: 0.2706\n",
      "Test Accuracy at Epoch 1180: 68.91%\n",
      "Test F1-score at Epoch 1180: 0.7155\n",
      "Classification Report at Epoch 1180:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.68      0.64      0.66       146\n",
      "non_infringement       0.70      0.73      0.72       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "New best model saved with F1-score 0.7155 at epoch 1180\n",
      "Best Classification Report at Epoch 1180:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.68      0.64      0.66       146\n",
      "non_infringement       0.70      0.73      0.72       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 1201/2000 [00:19<00:10, 73.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1190/2000, Loss: 0.2657\n",
      "Test Accuracy at Epoch 1190: 68.59%\n",
      "Test F1-score at Epoch 1190: 0.7048\n",
      "Classification Report at Epoch 1190:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.66      0.66       146\n",
      "non_infringement       0.70      0.70      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1200/2000, Loss: 0.2707\n",
      "Test Accuracy at Epoch 1200: 68.59%\n",
      "Test F1-score at Epoch 1200: 0.6859\n",
      "Classification Report at Epoch 1200:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.69       146\n",
      "non_infringement       0.73      0.64      0.69       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  61%|██████    | 1217/2000 [00:19<00:11, 70.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1210/2000, Loss: 0.2598\n",
      "Test Accuracy at Epoch 1210: 67.95%\n",
      "Test F1-score at Epoch 1210: 0.6855\n",
      "Classification Report at Epoch 1210:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.71      0.67       146\n",
      "non_infringement       0.72      0.66      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n",
      "Epoch 1220/2000, Loss: 0.2585\n",
      "Test Accuracy at Epoch 1220: 70.19%\n",
      "Test F1-score at Epoch 1220: 0.7273\n",
      "Classification Report at Epoch 1220:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.65      0.67       146\n",
      "non_infringement       0.71      0.75      0.73       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n",
      "New best model saved with F1-score 0.7273 at epoch 1220\n",
      "Best Classification Report at Epoch 1220:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.65      0.67       146\n",
      "non_infringement       0.71      0.75      0.73       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  62%|██████▏   | 1236/2000 [00:19<00:09, 76.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1230/2000, Loss: 0.2805\n",
      "Test Accuracy at Epoch 1230: 67.95%\n",
      "Test F1-score at Epoch 1230: 0.6753\n",
      "Classification Report at Epoch 1230:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.74      0.68       146\n",
      "non_infringement       0.73      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n",
      "Epoch 1240/2000, Loss: 0.2526\n",
      "Test Accuracy at Epoch 1240: 67.95%\n",
      "Test F1-score at Epoch 1240: 0.6933\n",
      "Classification Report at Epoch 1240:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.68      0.66       146\n",
      "non_infringement       0.71      0.68      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  63%|██████▎   | 1259/2000 [00:20<00:16, 46.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1250/2000, Loss: 0.3033\n",
      "Test Accuracy at Epoch 1250: 68.59%\n",
      "Test F1-score at Epoch 1250: 0.6839\n",
      "Classification Report at Epoch 1250:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.74      0.69       146\n",
      "non_infringement       0.74      0.64      0.68       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1260/2000, Loss: 0.2636\n",
      "Test Accuracy at Epoch 1260: 66.99%\n",
      "Test F1-score at Epoch 1260: 0.6623\n",
      "Classification Report at Epoch 1260:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.74      0.68       146\n",
      "non_infringement       0.73      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.68      0.67      0.67       312\n",
      "    weighted avg       0.68      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  64%|██████▍   | 1284/2000 [00:20<00:11, 64.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1270/2000, Loss: 0.2612\n",
      "Test Accuracy at Epoch 1270: 70.51%\n",
      "Test F1-score at Epoch 1270: 0.7278\n",
      "Classification Report at Epoch 1270:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.66      0.68       146\n",
      "non_infringement       0.72      0.74      0.73       166\n",
      "\n",
      "        accuracy                           0.71       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.71      0.70       312\n",
      "\n",
      "New best model saved with F1-score 0.7278 at epoch 1270\n",
      "Best Classification Report at Epoch 1270:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.66      0.68       146\n",
      "non_infringement       0.72      0.74      0.73       166\n",
      "\n",
      "        accuracy                           0.71       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.71      0.70       312\n",
      "\n",
      "Epoch 1280/2000, Loss: 0.2570\n",
      "Test Accuracy at Epoch 1280: 70.83%\n",
      "Test F1-score at Epoch 1280: 0.7316\n",
      "Classification Report at Epoch 1280:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.66      0.68       146\n",
      "non_infringement       0.72      0.75      0.73       166\n",
      "\n",
      "        accuracy                           0.71       312\n",
      "       macro avg       0.71      0.71      0.71       312\n",
      "    weighted avg       0.71      0.71      0.71       312\n",
      "\n",
      "New best model saved with F1-score 0.7316 at epoch 1280\n",
      "Best Classification Report at Epoch 1280:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.66      0.68       146\n",
      "non_infringement       0.72      0.75      0.73       166\n",
      "\n",
      "        accuracy                           0.71       312\n",
      "       macro avg       0.71      0.71      0.71       312\n",
      "    weighted avg       0.71      0.71      0.71       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|██████▌   | 1303/2000 [00:20<00:09, 76.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1290/2000, Loss: 0.2597\n",
      "Test Accuracy at Epoch 1290: 68.59%\n",
      "Test F1-score at Epoch 1290: 0.6818\n",
      "Classification Report at Epoch 1290:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.75      0.69       146\n",
      "non_infringement       0.74      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1300/2000, Loss: 0.2679\n",
      "Test Accuracy at Epoch 1300: 70.19%\n",
      "Test F1-score at Epoch 1300: 0.7207\n",
      "Classification Report at Epoch 1300:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.68      0.68      0.68       146\n",
      "non_infringement       0.72      0.72      0.72       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  66%|██████▌   | 1320/2000 [00:21<00:09, 69.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1310/2000, Loss: 0.2585\n",
      "Test Accuracy at Epoch 1310: 69.87%\n",
      "Test F1-score at Epoch 1310: 0.7235\n",
      "Classification Report at Epoch 1310:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.69      0.65      0.67       146\n",
      "non_infringement       0.71      0.74      0.72       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n",
      "Epoch 1320/2000, Loss: 0.2579\n",
      "Test Accuracy at Epoch 1320: 66.03%\n",
      "Test F1-score at Epoch 1320: 0.6603\n",
      "Classification Report at Epoch 1320:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.71      0.66       146\n",
      "non_infringement       0.71      0.62      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  67%|██████▋   | 1336/2000 [00:21<00:11, 59.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1330/2000, Loss: 0.2744\n",
      "Test Accuracy at Epoch 1330: 68.27%\n",
      "Test F1-score at Epoch 1330: 0.6817\n",
      "Classification Report at Epoch 1330:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.68       146\n",
      "non_infringement       0.73      0.64      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.69      0.69      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  68%|██████▊   | 1352/2000 [00:21<00:09, 67.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1340/2000, Loss: 0.2560\n",
      "Test Accuracy at Epoch 1340: 68.59%\n",
      "Test F1-score at Epoch 1340: 0.6818\n",
      "Classification Report at Epoch 1340:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.75      0.69       146\n",
      "non_infringement       0.74      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1350/2000, Loss: 0.2443\n",
      "Test Accuracy at Epoch 1350: 69.23%\n",
      "Test F1-score at Epoch 1350: 0.7073\n",
      "Classification Report at Epoch 1350:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.68      0.68       146\n",
      "non_infringement       0.72      0.70      0.71       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  69%|██████▊   | 1371/2000 [00:21<00:07, 79.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1360/2000, Loss: 0.2934\n",
      "Test Accuracy at Epoch 1360: 68.59%\n",
      "Test F1-score at Epoch 1360: 0.6818\n",
      "Classification Report at Epoch 1360:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.75      0.69       146\n",
      "non_infringement       0.74      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1370/2000, Loss: 0.2427\n",
      "Test Accuracy at Epoch 1370: 68.91%\n",
      "Test F1-score at Epoch 1370: 0.6840\n",
      "Classification Report at Epoch 1370:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.75      0.69       146\n",
      "non_infringement       0.74      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.70      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|██████▉   | 1391/2000 [00:21<00:06, 88.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1380/2000, Loss: 0.2397\n",
      "Test Accuracy at Epoch 1380: 68.27%\n",
      "Test F1-score at Epoch 1380: 0.6935\n",
      "Classification Report at Epoch 1380:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.69      0.67       146\n",
      "non_infringement       0.71      0.67      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n",
      "Epoch 1390/2000, Loss: 0.2382\n",
      "Test Accuracy at Epoch 1390: 67.95%\n",
      "Test F1-score at Epoch 1390: 0.6774\n",
      "Classification Report at Epoch 1390:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.68       146\n",
      "non_infringement       0.73      0.63      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 1410/2000 [00:22<00:07, 75.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1400/2000, Loss: 0.2350\n",
      "Test Accuracy at Epoch 1400: 69.55%\n",
      "Test F1-score at Epoch 1400: 0.6906\n",
      "Classification Report at Epoch 1400:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.76      0.70       146\n",
      "non_infringement       0.75      0.64      0.69       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n",
      "Epoch 1410/2000, Loss: 0.2648\n",
      "Test Accuracy at Epoch 1410: 67.95%\n",
      "Test F1-score at Epoch 1410: 0.7059\n",
      "Classification Report at Epoch 1410:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.63      0.65       146\n",
      "non_infringement       0.69      0.72      0.71       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  71%|███████▏  | 1426/2000 [00:22<00:08, 65.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1420/2000, Loss: 0.2421\n",
      "Test Accuracy at Epoch 1420: 68.91%\n",
      "Test F1-score at Epoch 1420: 0.7015\n",
      "Classification Report at Epoch 1420:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.69      0.68       146\n",
      "non_infringement       0.72      0.69      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1430/2000, Loss: 0.2328\n",
      "Test Accuracy at Epoch 1430: 69.87%\n",
      "Test F1-score at Epoch 1430: 0.7099\n",
      "Classification Report at Epoch 1430:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.71      0.69       146\n",
      "non_infringement       0.73      0.69      0.71       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.70      0.70      0.70       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  73%|███████▎  | 1453/2000 [00:22<00:08, 66.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1440/2000, Loss: 0.2309\n",
      "Test Accuracy at Epoch 1440: 67.95%\n",
      "Test F1-score at Epoch 1440: 0.6894\n",
      "Classification Report at Epoch 1440:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.69      0.67       146\n",
      "non_infringement       0.71      0.67      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n",
      "Epoch 1450/2000, Loss: 0.2630\n",
      "Test Accuracy at Epoch 1450: 68.59%\n",
      "Test F1-score at Epoch 1450: 0.6994\n",
      "Classification Report at Epoch 1450:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.68      0.67       146\n",
      "non_infringement       0.71      0.69      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  74%|███████▎  | 1470/2000 [00:23<00:07, 69.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1460/2000, Loss: 0.2387\n",
      "Test Accuracy at Epoch 1460: 69.55%\n",
      "Test F1-score at Epoch 1460: 0.7130\n",
      "Classification Report at Epoch 1460:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.68      0.68       146\n",
      "non_infringement       0.72      0.71      0.71       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n",
      "Epoch 1470/2000, Loss: 0.2345\n",
      "Test Accuracy at Epoch 1470: 69.55%\n",
      "Test F1-score at Epoch 1470: 0.7130\n",
      "Classification Report at Epoch 1470:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.68      0.68       146\n",
      "non_infringement       0.72      0.71      0.71       166\n",
      "\n",
      "        accuracy                           0.70       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.70      0.70      0.70       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  74%|███████▍  | 1486/2000 [00:23<00:07, 66.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1480/2000, Loss: 0.2272\n",
      "Test Accuracy at Epoch 1480: 67.95%\n",
      "Test F1-score at Epoch 1480: 0.6855\n",
      "Classification Report at Epoch 1480:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.71      0.67       146\n",
      "non_infringement       0.72      0.66      0.69       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n",
      "Epoch 1490/2000, Loss: 0.2603\n",
      "Test Accuracy at Epoch 1490: 67.63%\n",
      "Test F1-score at Epoch 1490: 0.6645\n",
      "Classification Report at Epoch 1490:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.76      0.69       146\n",
      "non_infringement       0.74      0.60      0.66       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  76%|███████▌  | 1510/2000 [00:23<00:06, 73.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/2000, Loss: 0.2365\n",
      "Test Accuracy at Epoch 1500: 68.59%\n",
      "Test F1-score at Epoch 1500: 0.7012\n",
      "Classification Report at Epoch 1500:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.68      0.67       146\n",
      "non_infringement       0.71      0.69      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.68      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1510/2000, Loss: 0.2383\n",
      "Test Accuracy at Epoch 1510: 68.59%\n",
      "Test F1-score at Epoch 1510: 0.7012\n",
      "Classification Report at Epoch 1510:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.68      0.67       146\n",
      "non_infringement       0.71      0.69      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.68      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  76%|███████▋  | 1527/2000 [00:23<00:06, 74.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1520/2000, Loss: 0.2375\n",
      "Test Accuracy at Epoch 1520: 67.95%\n",
      "Test F1-score at Epoch 1520: 0.6732\n",
      "Classification Report at Epoch 1520:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.75      0.69       146\n",
      "non_infringement       0.74      0.62      0.67       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n",
      "Epoch 1530/2000, Loss: 0.2704\n",
      "Test Accuracy at Epoch 1530: 68.27%\n",
      "Test F1-score at Epoch 1530: 0.6733\n",
      "Classification Report at Epoch 1530:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.76      0.69       146\n",
      "non_infringement       0.74      0.61      0.67       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.69      0.69      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  78%|███████▊  | 1551/2000 [00:24<00:06, 67.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1540/2000, Loss: 0.2247\n",
      "Test Accuracy at Epoch 1540: 68.27%\n",
      "Test F1-score at Epoch 1540: 0.6817\n",
      "Classification Report at Epoch 1540:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.73      0.68       146\n",
      "non_infringement       0.73      0.64      0.68       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.69      0.69      0.68       312\n",
      "    weighted avg       0.69      0.68      0.68       312\n",
      "\n",
      "Epoch 1550/2000, Loss: 0.2223\n",
      "Test Accuracy at Epoch 1550: 68.91%\n",
      "Test F1-score at Epoch 1550: 0.6997\n",
      "Classification Report at Epoch 1550:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.70      0.68       146\n",
      "non_infringement       0.72      0.68      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  78%|███████▊  | 1569/2000 [00:24<00:05, 75.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1560/2000, Loss: 0.2229\n",
      "Test Accuracy at Epoch 1560: 68.59%\n",
      "Test F1-score at Epoch 1560: 0.7012\n",
      "Classification Report at Epoch 1560:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.68      0.67       146\n",
      "non_infringement       0.71      0.69      0.70       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.68      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1570/2000, Loss: 0.4966\n",
      "Test Accuracy at Epoch 1570: 66.03%\n",
      "Test F1-score at Epoch 1570: 0.6490\n",
      "Classification Report at Epoch 1570:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.74      0.67       146\n",
      "non_infringement       0.72      0.59      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|███████▉  | 1593/2000 [00:24<00:05, 75.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1580/2000, Loss: 0.4300\n",
      "Test Accuracy at Epoch 1580: 61.22%\n",
      "Test F1-score at Epoch 1580: 0.6756\n",
      "Classification Report at Epoch 1580:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.45      0.52       146\n",
      "non_infringement       0.61      0.76      0.68       166\n",
      "\n",
      "        accuracy                           0.61       312\n",
      "       macro avg       0.61      0.60      0.60       312\n",
      "    weighted avg       0.61      0.61      0.60       312\n",
      "\n",
      "Epoch 1590/2000, Loss: 0.2990\n",
      "Test Accuracy at Epoch 1590: 65.71%\n",
      "Test F1-score at Epoch 1590: 0.6469\n",
      "Classification Report at Epoch 1590:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.73      0.67       146\n",
      "non_infringement       0.72      0.59      0.65       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 1610/2000 [00:25<00:05, 75.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1600/2000, Loss: 0.2588\n",
      "Test Accuracy at Epoch 1600: 65.71%\n",
      "Test F1-score at Epoch 1600: 0.6748\n",
      "Classification Report at Epoch 1600:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.64      0.64       146\n",
      "non_infringement       0.68      0.67      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 1610/2000, Loss: 0.2591\n",
      "Test Accuracy at Epoch 1610: 68.27%\n",
      "Test F1-score at Epoch 1610: 0.6991\n",
      "Classification Report at Epoch 1610:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.67      0.66       146\n",
      "non_infringement       0.71      0.69      0.70       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  81%|████████▏ | 1628/2000 [00:25<00:05, 67.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620/2000, Loss: 0.2495\n",
      "Test Accuracy at Epoch 1620: 66.35%\n",
      "Test F1-score at Epoch 1620: 0.6749\n",
      "Classification Report at Epoch 1620:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.67      0.65       146\n",
      "non_infringement       0.69      0.66      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  82%|████████▏ | 1636/2000 [00:25<00:06, 56.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1630/2000, Loss: 0.2457\n",
      "Test Accuracy at Epoch 1630: 66.35%\n",
      "Test F1-score at Epoch 1630: 0.6789\n",
      "Classification Report at Epoch 1630:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.66      0.65       146\n",
      "non_infringement       0.69      0.67      0.68       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 1640/2000, Loss: 0.2414\n",
      "Test Accuracy at Epoch 1640: 65.71%\n",
      "Test F1-score at Epoch 1640: 0.6728\n",
      "Classification Report at Epoch 1640:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.65      0.64       146\n",
      "non_infringement       0.68      0.66      0.67       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  83%|████████▎ | 1654/2000 [00:25<00:05, 68.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1650/2000, Loss: 0.2390\n",
      "Test Accuracy at Epoch 1650: 65.38%\n",
      "Test F1-score at Epoch 1650: 0.6687\n",
      "Classification Report at Epoch 1650:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.65      0.64       146\n",
      "non_infringement       0.68      0.66      0.67       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n",
      "Epoch 1660/2000, Loss: 0.2376\n",
      "Test Accuracy at Epoch 1660: 65.38%\n",
      "Test F1-score at Epoch 1660: 0.6687\n",
      "Classification Report at Epoch 1660:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.65      0.64       146\n",
      "non_infringement       0.68      0.66      0.67       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.65      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  84%|████████▍ | 1679/2000 [00:26<00:04, 70.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2000, Loss: 0.2673\n",
      "Test Accuracy at Epoch 1670: 66.67%\n",
      "Test F1-score at Epoch 1670: 0.6867\n",
      "Classification Report at Epoch 1670:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.64      0.64       146\n",
      "non_infringement       0.69      0.69      0.69       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n",
      "Epoch 1680/2000, Loss: 0.5477\n",
      "Test Accuracy at Epoch 1680: 62.18%\n",
      "Test F1-score at Epoch 1680: 0.6845\n",
      "Classification Report at Epoch 1680:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.45      0.53       146\n",
      "non_infringement       0.62      0.77      0.68       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.62      0.61      0.61       312\n",
      "    weighted avg       0.62      0.62      0.61       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  85%|████████▌ | 1707/2000 [00:26<00:03, 80.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1690/2000, Loss: 0.3014\n",
      "Test Accuracy at Epoch 1690: 66.67%\n",
      "Test F1-score at Epoch 1690: 0.6977\n",
      "Classification Report at Epoch 1690:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.60      0.63       146\n",
      "non_infringement       0.67      0.72      0.70       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.66      0.66       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n",
      "Epoch 1700/2000, Loss: 0.3238\n",
      "Test Accuracy at Epoch 1700: 66.99%\n",
      "Test F1-score at Epoch 1700: 0.6771\n",
      "Classification Report at Epoch 1700:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.69      0.66       146\n",
      "non_infringement       0.71      0.65      0.68       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  86%|████████▋ | 1727/2000 [00:26<00:03, 89.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1710/2000, Loss: 0.2723\n",
      "Test Accuracy at Epoch 1710: 69.23%\n",
      "Test F1-score at Epoch 1710: 0.7126\n",
      "Classification Report at Epoch 1710:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.66      0.67       146\n",
      "non_infringement       0.71      0.72      0.71       166\n",
      "\n",
      "        accuracy                           0.69       312\n",
      "       macro avg       0.69      0.69      0.69       312\n",
      "    weighted avg       0.69      0.69      0.69       312\n",
      "\n",
      "Epoch 1720/2000, Loss: 0.2641\n",
      "Test Accuracy at Epoch 1720: 68.27%\n",
      "Test F1-score at Epoch 1720: 0.7080\n",
      "Classification Report at Epoch 1720:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.67      0.64      0.65       146\n",
      "non_infringement       0.69      0.72      0.71       166\n",
      "\n",
      "        accuracy                           0.68       312\n",
      "       macro avg       0.68      0.68      0.68       312\n",
      "    weighted avg       0.68      0.68      0.68       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  87%|████████▋ | 1747/2000 [00:26<00:02, 93.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1730/2000, Loss: 0.2579\n",
      "Test Accuracy at Epoch 1730: 66.35%\n",
      "Test F1-score at Epoch 1730: 0.6809\n",
      "Classification Report at Epoch 1730:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.65      0.64       146\n",
      "non_infringement       0.69      0.67      0.68       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n",
      "Epoch 1740/2000, Loss: 0.2540\n",
      "Test Accuracy at Epoch 1740: 66.03%\n",
      "Test F1-score at Epoch 1740: 0.6788\n",
      "Classification Report at Epoch 1740:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.64      0.64       146\n",
      "non_infringement       0.68      0.67      0.68       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.66      0.66      0.66       312\n",
      "    weighted avg       0.66      0.66      0.66       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  88%|████████▊ | 1768/2000 [00:27<00:02, 96.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750/2000, Loss: 0.3287\n",
      "Test Accuracy at Epoch 1750: 66.35%\n",
      "Test F1-score at Epoch 1750: 0.6602\n",
      "Classification Report at Epoch 1750:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.72      0.67       146\n",
      "non_infringement       0.71      0.61      0.66       166\n",
      "\n",
      "        accuracy                           0.66       312\n",
      "       macro avg       0.67      0.67      0.66       312\n",
      "    weighted avg       0.67      0.66      0.66       312\n",
      "\n",
      "Epoch 1760/2000, Loss: 0.9334\n",
      "Test Accuracy at Epoch 1760: 58.65%\n",
      "Test F1-score at Epoch 1760: 0.6861\n",
      "Classification Report at Epoch 1760:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.29      0.39       146\n",
      "non_infringement       0.58      0.85      0.69       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.60      0.57      0.54       312\n",
      "    weighted avg       0.60      0.59      0.55       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  89%|████████▉ | 1779/2000 [00:27<00:02, 98.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1770/2000, Loss: 0.5697\n",
      "Test Accuracy at Epoch 1770: 51.28%\n",
      "Test F1-score at Epoch 1770: 0.2692\n",
      "Classification Report at Epoch 1770:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.49      0.90      0.63       146\n",
      "non_infringement       0.67      0.17      0.27       166\n",
      "\n",
      "        accuracy                           0.51       312\n",
      "       macro avg       0.58      0.54      0.45       312\n",
      "    weighted avg       0.58      0.51      0.44       312\n",
      "\n",
      "Epoch 1780/2000, Loss: 0.5558\n",
      "Test Accuracy at Epoch 1780: 49.36%\n",
      "Test F1-score at Epoch 1780: 0.2404\n",
      "Classification Report at Epoch 1780:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.48      0.88      0.62       146\n",
      "non_infringement       0.60      0.15      0.24       166\n",
      "\n",
      "        accuracy                           0.49       312\n",
      "       macro avg       0.54      0.52      0.43       312\n",
      "    weighted avg       0.54      0.49      0.42       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|████████▉ | 1799/2000 [00:27<00:02, 80.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1790/2000, Loss: 0.5320\n",
      "Test Accuracy at Epoch 1790: 61.54%\n",
      "Test F1-score at Epoch 1790: 0.5489\n",
      "Classification Report at Epoch 1790:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.56      0.82      0.66       146\n",
      "non_infringement       0.73      0.44      0.55       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.65      0.63      0.61       312\n",
      "    weighted avg       0.65      0.62      0.60       312\n",
      "\n",
      "Epoch 1800/2000, Loss: 0.4971\n",
      "Test Accuracy at Epoch 1800: 65.38%\n",
      "Test F1-score at Epoch 1800: 0.7000\n",
      "Classification Report at Epoch 1800:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.66      0.53      0.59       146\n",
      "non_infringement       0.65      0.76      0.70       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.65      0.65       312\n",
      "    weighted avg       0.65      0.65      0.65       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  91%|█████████ | 1824/2000 [00:27<00:02, 73.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1810/2000, Loss: 0.5615\n",
      "Test Accuracy at Epoch 1810: 58.01%\n",
      "Test F1-score at Epoch 1810: 0.6797\n",
      "Classification Report at Epoch 1810:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.29      0.39       146\n",
      "non_infringement       0.57      0.84      0.68       166\n",
      "\n",
      "        accuracy                           0.58       312\n",
      "       macro avg       0.59      0.56      0.54       312\n",
      "    weighted avg       0.59      0.58      0.54       312\n",
      "\n",
      "Epoch 1820/2000, Loss: 0.5571\n",
      "Test Accuracy at Epoch 1820: 58.97%\n",
      "Test F1-score at Epoch 1820: 0.6816\n",
      "Classification Report at Epoch 1820:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.62      0.32      0.42       146\n",
      "non_infringement       0.58      0.83      0.68       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.60      0.57      0.55       312\n",
      "    weighted avg       0.60      0.59      0.56       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  92%|█████████▏| 1832/2000 [00:27<00:02, 73.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1830/2000, Loss: 0.5214\n",
      "Test Accuracy at Epoch 1830: 63.78%\n",
      "Test F1-score at Epoch 1830: 0.6781\n",
      "Classification Report at Epoch 1830:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.55      0.59       146\n",
      "non_infringement       0.64      0.72      0.68       166\n",
      "\n",
      "        accuracy                           0.64       312\n",
      "       macro avg       0.64      0.63      0.63       312\n",
      "    weighted avg       0.64      0.64      0.64       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  92%|█████████▎| 1850/2000 [00:28<00:02, 59.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1840/2000, Loss: 0.5542\n",
      "Test Accuracy at Epoch 1840: 61.22%\n",
      "Test F1-score at Epoch 1840: 0.6952\n",
      "Classification Report at Epoch 1840:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.65      0.36      0.47       146\n",
      "non_infringement       0.60      0.83      0.70       166\n",
      "\n",
      "        accuracy                           0.61       312\n",
      "       macro avg       0.63      0.60      0.58       312\n",
      "    weighted avg       0.62      0.61      0.59       312\n",
      "\n",
      "Epoch 1850/2000, Loss: 0.5571\n",
      "Test Accuracy at Epoch 1850: 58.65%\n",
      "Test F1-score at Epoch 1850: 0.6861\n",
      "Classification Report at Epoch 1850:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.29      0.39       146\n",
      "non_infringement       0.58      0.85      0.69       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.60      0.57      0.54       312\n",
      "    weighted avg       0.60      0.59      0.55       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  93%|█████████▎| 1869/2000 [00:28<00:01, 71.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1860/2000, Loss: 0.5465\n",
      "Test Accuracy at Epoch 1860: 58.65%\n",
      "Test F1-score at Epoch 1860: 0.6861\n",
      "Classification Report at Epoch 1860:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.29      0.39       146\n",
      "non_infringement       0.58      0.85      0.69       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.60      0.57      0.54       312\n",
      "    weighted avg       0.60      0.59      0.55       312\n",
      "\n",
      "Epoch 1870/2000, Loss: 0.5368\n",
      "Test Accuracy at Epoch 1870: 58.65%\n",
      "Test F1-score at Epoch 1870: 0.6861\n",
      "Classification Report at Epoch 1870:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.63      0.29      0.39       146\n",
      "non_infringement       0.58      0.85      0.69       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.60      0.57      0.54       312\n",
      "    weighted avg       0.60      0.59      0.55       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  94%|█████████▍| 1888/2000 [00:28<00:01, 71.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1880/2000, Loss: 0.5211\n",
      "Test Accuracy at Epoch 1880: 56.41%\n",
      "Test F1-score at Epoch 1880: 0.6583\n",
      "Classification Report at Epoch 1880:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.56      0.31      0.40       146\n",
      "non_infringement       0.56      0.79      0.66       166\n",
      "\n",
      "        accuracy                           0.56       312\n",
      "       macro avg       0.56      0.55      0.53       312\n",
      "    weighted avg       0.56      0.56      0.54       312\n",
      "\n",
      "Epoch 1890/2000, Loss: 0.4993\n",
      "Test Accuracy at Epoch 1890: 60.90%\n",
      "Test F1-score at Epoch 1890: 0.6685\n",
      "Classification Report at Epoch 1890:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.46      0.52       146\n",
      "non_infringement       0.61      0.74      0.67       166\n",
      "\n",
      "        accuracy                           0.61       312\n",
      "       macro avg       0.61      0.60      0.60       312\n",
      "    weighted avg       0.61      0.61      0.60       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  95%|█████████▌| 1904/2000 [00:29<00:01, 61.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1900/2000, Loss: 0.4878\n",
      "Test Accuracy at Epoch 1900: 59.29%\n",
      "Test F1-score at Epoch 1900: 0.6501\n",
      "Classification Report at Epoch 1900:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.58      0.46      0.51       146\n",
      "non_infringement       0.60      0.71      0.65       166\n",
      "\n",
      "        accuracy                           0.59       312\n",
      "       macro avg       0.59      0.58      0.58       312\n",
      "    weighted avg       0.59      0.59      0.59       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  96%|█████████▌| 1917/2000 [00:29<00:01, 55.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1910/2000, Loss: 0.5200\n",
      "Test Accuracy at Epoch 1910: 62.18%\n",
      "Test F1-score at Epoch 1910: 0.6488\n",
      "Classification Report at Epoch 1910:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.60      0.58      0.59       146\n",
      "non_infringement       0.64      0.66      0.65       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.62      0.62      0.62       312\n",
      "    weighted avg       0.62      0.62      0.62       312\n",
      "\n",
      "Epoch 1920/2000, Loss: 0.5525\n",
      "Test Accuracy at Epoch 1920: 66.67%\n",
      "Test F1-score at Epoch 1920: 0.6810\n",
      "Classification Report at Epoch 1920:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.64      0.66      0.65       146\n",
      "non_infringement       0.69      0.67      0.68       166\n",
      "\n",
      "        accuracy                           0.67       312\n",
      "       macro avg       0.67      0.67      0.67       312\n",
      "    weighted avg       0.67      0.67      0.67       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  97%|█████████▋| 1940/2000 [00:29<00:00, 65.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1930/2000, Loss: 0.5587\n",
      "Test Accuracy at Epoch 1930: 51.28%\n",
      "Test F1-score at Epoch 1930: 0.2475\n",
      "Classification Report at Epoch 1930:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.49      0.92      0.64       146\n",
      "non_infringement       0.69      0.15      0.25       166\n",
      "\n",
      "        accuracy                           0.51       312\n",
      "       macro avg       0.59      0.54      0.44       312\n",
      "    weighted avg       0.60      0.51      0.43       312\n",
      "\n",
      "Epoch 1940/2000, Loss: 0.5467\n",
      "Test Accuracy at Epoch 1940: 61.54%\n",
      "Test F1-score at Epoch 1940: 0.5714\n",
      "Classification Report at Epoch 1940:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.57      0.77      0.65       146\n",
      "non_infringement       0.70      0.48      0.57       166\n",
      "\n",
      "        accuracy                           0.62       312\n",
      "       macro avg       0.63      0.62      0.61       312\n",
      "    weighted avg       0.64      0.62      0.61       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  98%|█████████▊| 1960/2000 [00:29<00:00, 81.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1950/2000, Loss: 0.5385\n",
      "Test Accuracy at Epoch 1950: 65.06%\n",
      "Test F1-score at Epoch 1950: 0.6450\n",
      "Classification Report at Epoch 1950:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.61      0.71      0.66       146\n",
      "non_infringement       0.70      0.60      0.64       166\n",
      "\n",
      "        accuracy                           0.65       312\n",
      "       macro avg       0.66      0.65      0.65       312\n",
      "    weighted avg       0.66      0.65      0.65       312\n",
      "\n",
      "Epoch 1960/2000, Loss: 0.5401\n",
      "Test Accuracy at Epoch 1960: 51.28%\n",
      "Test F1-score at Epoch 1960: 0.2475\n",
      "Classification Report at Epoch 1960:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.49      0.92      0.64       146\n",
      "non_infringement       0.69      0.15      0.25       166\n",
      "\n",
      "        accuracy                           0.51       312\n",
      "       macro avg       0.59      0.54      0.44       312\n",
      "    weighted avg       0.60      0.51      0.43       312\n",
      "\n",
      "Epoch 1970/2000, Loss: 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  99%|█████████▉| 1980/2000 [00:30<00:00, 87.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy at Epoch 1970: 51.28%\n",
      "Test F1-score at Epoch 1970: 0.2475\n",
      "Classification Report at Epoch 1970:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.49      0.92      0.64       146\n",
      "non_infringement       0.69      0.15      0.25       166\n",
      "\n",
      "        accuracy                           0.51       312\n",
      "       macro avg       0.59      0.54      0.44       312\n",
      "    weighted avg       0.60      0.51      0.43       312\n",
      "\n",
      "Epoch 1980/2000, Loss: 0.5438\n",
      "Test Accuracy at Epoch 1980: 51.28%\n",
      "Test F1-score at Epoch 1980: 0.2475\n",
      "Classification Report at Epoch 1980:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.49      0.92      0.64       146\n",
      "non_infringement       0.69      0.15      0.25       166\n",
      "\n",
      "        accuracy                           0.51       312\n",
      "       macro avg       0.59      0.54      0.44       312\n",
      "    weighted avg       0.60      0.51      0.43       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 2000/2000 [00:30<00:00, 65.69it/s]\n",
      "/tmp/ipykernel_1187691/3077705936.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  custom_mlp.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1990/2000, Loss: 0.5327\n",
      "Test Accuracy at Epoch 1990: 56.09%\n",
      "Test F1-score at Epoch 1990: 0.3744\n",
      "Classification Report at Epoch 1990:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.52      0.92      0.66       146\n",
      "non_infringement       0.77      0.25      0.37       166\n",
      "\n",
      "        accuracy                           0.56       312\n",
      "       macro avg       0.65      0.58      0.52       312\n",
      "    weighted avg       0.65      0.56      0.51       312\n",
      "\n",
      "Epoch 2000/2000, Loss: 0.5201\n",
      "Test Accuracy at Epoch 2000: 58.33%\n",
      "Test F1-score at Epoch 2000: 0.4538\n",
      "Classification Report at Epoch 2000:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.53      0.88      0.66       146\n",
      "non_infringement       0.75      0.33      0.45       166\n",
      "\n",
      "        accuracy                           0.58       312\n",
      "       macro avg       0.64      0.60      0.56       312\n",
      "    weighted avg       0.65      0.58      0.55       312\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model was saved at epoch 1280 with F1-score 0.7316 and accuracy 70.83%\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 256\n",
    "\n",
    "custom_mlp, losses, best_accuracy, best_f1 = train_model(X_train, y_train, X_test, y_test, input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/models/train_input_last_token.pth'.\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to '{filepath}'.\")\n",
    "\n",
    "save_checkpoint(custom_mlp, torch.optim.Adam(custom_mlp.parameters()), len(losses), losses[-1], checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 70.83%\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    infringement       0.70      0.66      0.68       146\n",
      "non_infringement       0.72      0.75      0.73       166\n",
      "\n",
      "        accuracy                           0.71       312\n",
      "       macro avg       0.71      0.71      0.71       312\n",
      "    weighted avg       0.71      0.71      0.71       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1187691/3740627605.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred_final = (torch.sigmoid(torch.tensor(custom_mlp(torch.tensor(X_test, dtype=torch.float32)))) > 0.5).float().numpy()\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Final Model Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "y_pred_final = (torch.sigmoid(torch.tensor(custom_mlp(torch.tensor(X_test, dtype=torch.float32)))) > 0.5).float().numpy()\n",
    "print(classification_report(y_test, y_pred_final, target_names=[\"infringement\", \"non_infringement\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
